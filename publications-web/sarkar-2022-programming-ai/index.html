<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Advait Sarkar" />
  <title>What is it like to program with artificial intelligence?</title>
  <link rel="stylesheet" href="/main.css">
  <link rel="stylesheet" href="/publications-web/publications-web.css">
</head>
<body>

<h2><a href="/">&larr; advait.org</a></h2>

<div class="publications-web-banner">
<p>This is a version of the following academic paper prepared for the web:</p>

<blockquote>Advait Sarkar, Andrew D. Gordon, Carina Negreanu, Christian Poelitz, Sruti Srinivasa Ragavan, Ben Zorn. "What is it like to program with artificial intelligence?" Proceedings of the 33rd Annual Conference of the Psychology of Programming Interest Group (PPIG 2022). 2022.</blockquote>

<p>
More details:
<a href="/files/sarkar_2022_programming_ai.pdf">Download PDF</a> &bull; 
<a href="/files/sarkar_2022_programming_ai_citation.bib">BibTeX</a> &bull;
<a href="https://arxiv.org/abs/2208.06213">arXiv:2208.06213</a>
</p>
</div>

<header id="title-block-header">
<h1 class="title">What is it like to program with artificial intelligence?</h1>

<p class="author">
Advait Sarkar, Andrew D. Gordon, Carina Negreanu, Christian Poelitz, Sruti Srinivasa Ragavan, Ben Zorn
</p>
</header>

<div class="abstract">
<h2>Abstract</h2>
<p>Large language models, such as OpenAI’s codex and Deepmind’s
AlphaCode, can generate code to solve a variety of problems expressed in
natural language. This technology has already been commercialised in at
least one widely-used programming editor extension: GitHub Copilot.</p>
<p>In this paper, we explore how programming with large language models
(LLM-assisted programming) is similar to, and differs from, prior
conceptualisations of programmer assistance. We draw upon publicly
available experience reports of LLM-assisted programming, as well as
prior usability and design studies. We find that while LLM-assisted
programming shares some properties of compilation, pair programming, and
programming via search and reuse, there are fundamental differences both
in the technical possibilities as well as the practical experience.
Thus, LLM-assisted programming ought to be viewed as a new way of
programming with its own distinct properties and challenges.</p>
<p>Finally, we draw upon observations from a user study in which
non-expert end user programmers use LLM-assisted tools for solving data
tasks in spreadsheets. We discuss the issues that might arise, and open
research challenges, in applying large language models to end-user
programming, particularly with users who have little or no programming
expertise.</p>
</div>

<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction"><span
class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#sec:prior_models" id="toc-sec:prior_models"><span
class="toc-section-number">2</span> Prior conceptualisations of
intelligent assistance for programmers</a></li>
<li><a href="#sec:large_language_models"
id="toc-sec:large_language_models"><span
class="toc-section-number">3</span> A brief overview of large language
models for code generation</a>
<ul>
<li><a
href="#the-transformer-architecture-and-big-datasets-enable-large-pre-trained-models"
id="toc-the-transformer-architecture-and-big-datasets-enable-large-pre-trained-models"><span
class="toc-section-number">3.1</span> The transformer architecture and
big datasets enable large pre-trained models</a></li>
<li><a href="#language-models-tuned-for-source-code-generation"
id="toc-language-models-tuned-for-source-code-generation"><span
class="toc-section-number">3.2</span> Language models tuned for source
code generation</a></li>
</ul></li>
<li><a href="#sec:commercial" id="toc-sec:commercial"><span
class="toc-section-number">4</span> Commercial programming tools that
use large language models</a></li>
<li><a href="#sec:reliability" id="toc-sec:reliability"><span
class="toc-section-number">5</span> Reliability, safety, and security
implications of code-generating AI models</a></li>
<li><a href="#sec:prior_studies" id="toc-sec:prior_studies"><span
class="toc-section-number">6</span> Usability and design studies of
AI-assisted programming</a></li>
<li><a href="#sec:experience_reports"
id="toc-sec:experience_reports"><span
class="toc-section-number">7</span> Experience reports</a>
<ul>
<li><a href="#writing-effective-prompts-is-hard"
id="toc-writing-effective-prompts-is-hard"><span
class="toc-section-number">7.1</span> Writing effective prompts is
hard</a></li>
<li><a
href="#the-activity-of-programming-shifts-towards-checking-and-unfamiliar-debugging"
id="toc-the-activity-of-programming-shifts-towards-checking-and-unfamiliar-debugging"><span
class="toc-section-number">7.2</span> The activity of programming shifts
towards checking and unfamiliar debugging</a></li>
<li><a href="#these-tools-are-useful-for-boilerplate-and-code-reuse"
id="toc-these-tools-are-useful-for-boilerplate-and-code-reuse"><span
class="toc-section-number">7.3</span> These tools are useful for
boilerplate and code reuse</a></li>
</ul></li>
<li><a href="#sec:metaphors" id="toc-sec:metaphors"><span
class="toc-section-number">8</span> The inadequacy of existing metaphors
for AI-assisted programming</a>
<ul>
<li><a href="#ai-assistance-as-search"
id="toc-ai-assistance-as-search"><span
class="toc-section-number">8.1</span> AI assistance as search</a></li>
<li><a href="#ai-assistance-as-compilation"
id="toc-ai-assistance-as-compilation"><span
class="toc-section-number">8.2</span> AI assistance as
compilation</a></li>
<li><a href="#ai-assistance-as-pair-programming"
id="toc-ai-assistance-as-pair-programming"><span
class="toc-section-number">8.3</span> AI assistance as pair
programming</a></li>
<li><a href="#a-distinct-way-of-programming"
id="toc-a-distinct-way-of-programming"><span
class="toc-section-number">8.4</span> A distinct way of
programming</a></li>
</ul></li>
<li><a href="#sec:eup" id="toc-sec:eup"><span
class="toc-section-number">9</span> Issues with application to end-user
programming</a>
<ul>
<li><a
href="#issue-1-intent-specification-problem-decomposition-and-computational-thinking"
id="toc-issue-1-intent-specification-problem-decomposition-and-computational-thinking"><span
class="toc-section-number">9.1</span> Issue 1: Intent specification,
problem decomposition and computational thinking</a></li>
<li><a href="#issue-2-code-correctness-quality-and-overconfidence"
id="toc-issue-2-code-correctness-quality-and-overconfidence"><span
class="toc-section-number">9.2</span> Issue 2: Code correctness, quality
and (over)confidence</a></li>
<li><a href="#issue-3-code-comprehension-and-maintenance"
id="toc-issue-3-code-comprehension-and-maintenance"><span
class="toc-section-number">9.3</span> Issue 3: Code comprehension and
maintenance</a></li>
<li><a
href="#issue-4-consequences-of-automation-in-end-user-programming"
id="toc-issue-4-consequences-of-automation-in-end-user-programming"><span
class="toc-section-number">9.4</span> Issue 4: Consequences of
automation in end-user programming</a></li>
<li><a href="#issue-5-no-code-and-the-dilemma-of-the-direct-answer"
id="toc-issue-5-no-code-and-the-dilemma-of-the-direct-answer"><span
class="toc-section-number">9.5</span> Issue 5: No code, and the dilemma
of the direct answer</a></li>
</ul></li>
<li><a href="#sec:conclusion" id="toc-sec:conclusion"><span
class="toc-section-number">10</span> Conclusion</a></li>
<li><a href="#apx:experience_report_sources"
id="toc-apx:experience_report_sources"><span
class="toc-section-number">11</span> Experience report sources</a>
<ul>
<li><a href="#blog-posts-and-corresponding-hacker-news-discussions"
id="toc-blog-posts-and-corresponding-hacker-news-discussions"><span
class="toc-section-number">11.1</span> Blog posts and corresponding
Hacker News discussions</a></li>
<li><a href="#miscellaneous-hacker-news-discussions"
id="toc-miscellaneous-hacker-news-discussions"><span
class="toc-section-number">11.2</span> Miscellaneous Hacker News
discussions</a></li>
</ul></li>
</ul>
</nav>
<figure>
<img src="copilot1.png" id="fig:copilot1"
alt="Code generation using the GitHub Copilot editor extension. The portion highlighted in blue has been generated by the model. Left: a function body, generated based on a textual description in a comment. Right: a set of generated test cases. Source: copilot.github.com" />
<figcaption aria-hidden="true">Figure 1 - Code generation using the GitHub Copilot
editor extension. The portion highlighted in blue has been generated by
the model. Left: a function body, generated based on a textual
description in a comment. Right: a set of generated test cases. Source:
<a href="copilot.github.com"
class="uri">copilot.github.com</a></figcaption>
</figure>
<h2 data-number="1" id="introduction"><span
class="header-section-number">1</span> Introduction</h2>
<p>Inferential assistance for programmers has manifested in various
forms, such as programming by demonstration, declarative programming
languages, and program synthesis (Section <a href="#sec:prior_models"
data-reference-type="ref" data-reference="sec:prior_models">2</a>).
Large language models such as GPT mark a quantitative and qualitative
step-change in the automatic generation of code and natural language
text. This can be attributed to cumulative innovations of vector-space
word embeddings, the transformer architecture, large text corpora, and
pre-trained language models (Section <a
href="#sec:large_language_models" data-reference-type="ref"
data-reference="sec:large_language_models">3</a>).</p>
<p>These models have been commercialised in the form of APIs such as
OpenAI Codex, or as programmer-facing tools such as GitHub Copilot and
Tabnine. These tools function as a sort of advanced autocomplete, able
to synthesize multiple lines of code based on a prompt within the code
editor, which may be natural language (e.g., a comment), code (e.g., a
function signature) or an ad-hoc mixture. The capabilities of such tools
go well beyond traditional syntax-directed autocomplete, and include the
ability to synthesize entire function bodies, write test cases, and
complete repetitive patterns (Section <a href="#sec:commercial"
data-reference-type="ref" data-reference="sec:commercial">4</a>). These
tools have reliability, safety, and security implications (Section <a
href="#sec:reliability" data-reference-type="ref"
data-reference="sec:reliability">5</a>).</p>
<p>Prior lab-based and telemetric research on the usability of such
tools finds that developers generally appreciate the capabilities of
these tools and find them to be a positive asset to the development
experience, despite no strong effects on task completion times or
correctness. Core usability issues include the challenge of correctly
framing prompts as well as the effort required to check and debug
generated code (Section <a href="#sec:prior_studies"
data-reference-type="ref" data-reference="sec:prior_studies">6</a>).</p>
<p>Longitudinal experience reports of developers support some of the
lab-based findings, while contradicting others. The challenges of
correctly framing prompts and the efforts of debugging also appear here.
However, there are many reports that these tools do in fact strongly
reduce task time (i.e., speed up the development process) (Section <a
href="#sec:experience_reports" data-reference-type="ref"
data-reference="sec:experience_reports">7</a>).</p>
<p>Programming with large language models invites comparison to related
ways of programming, such as search, compilation, and pair programming.
While there are indeed similarities with each of these, the empirical
reports of the experience of such tools also show crucial differences.
Search, compilation, and pair programming are thus found to be
inadequate metaphors for the nature of LLM-assisted programming; it is a
distinct way of programming with its own unique blend of properties
(Section <a href="#sec:metaphors" data-reference-type="ref"
data-reference="sec:metaphors">8</a>).</p>
<p>While LLM-assisted programming is currently geared towards expert
programmers, arguably the greatest beneficiaries of their abilities will
be non-expert end-user programmers. Nonetheless, there are issues with
their direct application in end-user programming scenarios. Through a
study of LLM-assisted end-user programming in spreadsheets, we uncover
issues in intent specification, code correctness, comprehension, LLM
tuning, and end-user behaviour, and motivate the need for further study
in this area (Section <a href="#sec:eup" data-reference-type="ref"
data-reference="sec:eup">9</a>).</p>
<h2 data-number="2" id="sec:prior_models"><span
class="header-section-number">2</span> Prior conceptualisations of
intelligent assistance for programmers</h2>
<p>What counts as ‘intelligent assistance’ can be the subject of some
debate. Do we select only features that are driven by technologies that
the artificial intelligence research community (itself undefined) would
recognise as artificial intelligence? Do we include those that use
expert-coded heuristics? Systems that make inferences a human might
disagree with, or those with the potential for error? Mixed-initiative
systems <span class="citation"
data-cites="horvitz1999principles">(Horvitz 1999)</span>? Or those that
make the user feel intelligent, assisted, or empowered? While this
debate is beyond the scope of this paper, we feel that to properly
contextualise the qualitative difference made by large language models,
a broad and inclusive approach to the term ‘intelligence’ is
required.</p>
<p>End-user programming has long been home to inferential, or
intelligent assistance. The strategy of direct manipulation <span
class="citation" data-cites="shneiderman1993direct">(Shneiderman and
Norwood 1993)</span> is highly successful for certain types of limited,
albeit useful, computational tasks, where the interface being used
(“what you see”, e.g., a text editor or an image editor) to develop an
information artefact can represent closely the artefact being developed
(“what you get”, e.g., a text document or an image). However, this
strategy cannot be straightforwardly applied to programs. Programs
notate multiple possible paths of execution simultaneously, and they
define “behaviour to occur at some future time” <span class="citation"
data-cites="blackwell2002programming">(Blackwell 2002b)</span>.
Rendering multiple futures in the present is a core problem of live
programming research <span class="citation"
data-cites="tanimoto2013perspective">(Tanimoto 2013)</span>, which aims
to externalise programs as they are edited <span class="citation"
data-cites="basman2016software">(Basman et al. 2016)</span>.</p>
<p>The need to bridge the abstraction gap between direct manipulation
and multiple paths of execution led to the invention of programming by
demonstration (PBD) <span class="citation"
data-cites="kurlander1993watch lieberman2001your myers1992demonstrational">(Kurlander,
Cypher, and Halbert 1993; Lieberman 2001; Myers 1992)</span>. A form of
inferential assistance, PBD allows end-user programmers to make concrete
demonstrations of desired behaviour that are generalised into executable
programs. Despite their promise, PBD systems have not achieved
widespread success as end-user programming tools, although their idea
survives in vestigial form as various “macro recording” tools, and the
approach is seeing a resurgence with the growing commercialisation of
“robotic process automation”.</p>
<p>Programming language design has long been concerned with shifting the
burden of intelligence between programmer, program, compiler, and user.
Programming language compilers, in translating between high-level
languages and machine code, are a kind of intelligent assistance for
programmers. The declarative language Prolog aspired to bring a kind of
intelligence, where the programmer would only be responsible for
specifying (“declaring”) <em>what</em> to compute, but not <em>how</em>
to compute it; that responsibility was left to the interpreter. At the
same time, the language was designed with intelligent applications in
mind. Indeed, it found widespread use within artificial intelligence and
computational linguistics research <span class="citation"
data-cites="colmerauer1996birth rouchy2006aspects">(Colmerauer and
Roussel 1996; Rouchy 2006)</span>.</p>
<p>Formal verification tools use a specification language, such as Hoare
triples <span class="citation"
data-cites="DBLP:journals/cacm/Hoare69">(Hoare 1969)</span>, and writing
such specifications can be considered programming at a ‘higher’ level of
abstraction. Program synthesis, in particular synthesis through
refinement, aims at intelligently transforming these rules into
executable and correct code. However, the term “program synthesis” is
also used more broadly, and programs can be synthesised from other
sources than higher-level specifications. Concretely, program synthesis
by example, or simply programming by example (PBE), facilitates the
generation of executable code from input-output examples. An example of
successfully commercialised PBE is Excel’s Flash Fill <span
class="citation" data-cites="DBLP:conf/popl/Gulwani11">(Gulwani
2011)</span>, which synthesises string transformations in spreadsheets
from a small number of examples.</p>
<p>The Cognitive Dimensions framework <span class="citation"
data-cites="green1989cognitive green1998cognitive">(T. R. Green 1989; T.
Green and Blackwell 1998)</span> identifies three categories of
programming activity: authoring, transcription, and modification. Modern
programmer assistance encompasses each of these. For example, program
synthesis tools transform the direct authoring of code into the
(arguably easier) authoring of examples. Intelligent code completions
<span class="citation" data-cites="marasoiu2015empirical">(Marasoiu,
Church, and Blackwell 2015)</span> support the direct authoring of code.
Intelligent support for reuse, such as smart code copy/paste <span
class="citation" data-cites="allamanis2017smartpaste">(Allamanis and
Brockschmidt 2017)</span> support transcription, and refactoring tools
<span class="citation" data-cites="hermans2015detecting">(Hermans,
Pinzger, and Deursen 2015)</span> support modification. Researchers have
investigated inferential support for navigating source code <span
class="citation" data-cites="henley2014patchworks">(Henley and Fleming
2014)</span>, debugging <span class="citation"
data-cites="williams2020understanding">(J. Williams et al. 2020)</span>,
and selectively undoing code changes <span class="citation"
data-cites="yoon2015supporting">(Yoon and Myers 2015)</span>.
Additionally, intelligent tools can also support learning <span
class="citation" data-cites="cao2015idea">(Cao et al. 2015)</span>.</p>
<p><span class="citation"
data-cites="DBLP:journals/csur/AllamanisBDS18">Allamanis et al. (2018)</span> review work at the intersection of machine learning,
programming languages, and software engineering. They seek to adapt
methods first developed for natural language, such as language models,
to source code. The emergence of large bodies of open source code,
sometimes called “big code”, enabled this research area. Language models
are sensitive to lexical features like names, code formatting, and order
of methods, while traditional tools like compilers or code verifiers are
not. Through the “naturalness hypothesis”, which claims that “software
is a form of human communication; software corpora have similar
statistical properties to natural language corpora; the authors claim
that these properties can be exploited to build better software
engineering tools.” Some support for this hypothesis comes from research
that used <span class="math inline"><em>n</em></span>-gram models to
build a code completion engine for Java that outperformed Eclipse’s
completion feature <span class="citation"
data-cites="DBLP:conf/icse/HindleBSGD12 DBLP:journals/cacm/HindleBGS16">(Hindle
et al. 2012, 2016)</span>. This approach can underpin recommender
systems (such as code autocompletion), debuggers, code analysers (such
as type checkers <span class="citation"
data-cites="DBLP:conf/popl/RaychevVK15">(Raychev, Vechev, and Krause
2015)</span>), and code synthesizers. We can expect the recent expansion
in capability of language models, discussed next, to magnify the
effectiveness of these applications.</p>
<h2 data-number="3" id="sec:large_language_models"><span
class="header-section-number">3</span> A brief overview of large
language models for code generation</h2>
<h3 data-number="3.1"
id="the-transformer-architecture-and-big-datasets-enable-large-pre-trained-models"><span
class="header-section-number">3.1</span> The transformer architecture
and big datasets enable large pre-trained models</h3>
<p>In the 2010s, natural language processing has evolved in the
development of language models (LMs), tasks, and evaluation. <span
class="citation" data-cites="NIPS2013_9aa42b31">Mikolov et al.
(2013)</span> introduced Word2Vec, where vectors are assigned to words
such that similar words are grouped together. It relies on
co-occurrences in text (like Wikipedia articles), though simple
instantiations ignore the fact that words can have multiple meanings
depending on context. Long short-term memory (LSTM) neural networks
<span class="citation"
data-cites="10.1162/neco.1997.9.8.1735 10.5555/2969033.2969173">(Hochreiter
and Schmidhuber 1997; Sutskever, Vinyals, and Le 2014)</span> and later
encoder-decoder networks, account for order in an input sequence.
Self-attention <span class="citation"
data-cites="10.5555/3295222.3295349">(Vaswani et al. 2017)</span>
significantly simplified prior networks by replacing each element in the
input by a weighted average of the rest of the input. Transformers
combined the advantages of (multi-head) attention and word embeddings,
enriched with positional encodings (which add order information to the
word embeddings) into one architecture. While there are many
alternatives to transformers for language modelling, in this paper when
we mention a language model we will usually imply a transformer-based
language model.</p>
<p>There are large collections of unlabelled text for some widely-spoken
natural languages. For example, the Common Crawl project<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
produces around 20 TB of text data (from web pages) monthly. Labelled
task-specific data is less prevalent. This makes unsupervised training
appealing. Pre-trained LMs <span class="citation"
data-cites="ijcai2021-612">(J. Li et al. 2021)</span> are commonly
trained to perform next-word prediction (e.g., GPT <span
class="citation" data-cites="brown2020language">(Brown et al.
2020)</span>) or filling a gap in a sequence (e.g., BERT <span
class="citation" data-cites="devlin-etal-2019-bert">(Devlin et al.
2019)</span>).</p>
<p>Ideally, the “general knowledge” learnt by pre-trained LMs can then
be transferred to downstream language tasks (where we have less labelled
data) such as question answering, fiction generation, text
summarisation, etc. Fine-tuning is the process of adapting a given
pre-trained LM to different downstream tasks by introducing additional
parameters and training them using task-specific objective functions. In
certain cases the pre-training objective also gets adjusted to better
suit the downstream task. Instead of (or on top of) fine-tuning, the
downstream task can be reformulated to be similar to the original LLM
training. In practice, this means expressing the task as a set of
instructions to the LLM via a prompt. So the goal, rather than defining
a learning objective for a given task, is to find a way to query the LLM
to directly predict for the downstream task. This is sometimes referred
to as Pre-train, Prompt, Predict.<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h3 data-number="3.2"
id="language-models-tuned-for-source-code-generation"><span
class="header-section-number">3.2</span> Language models tuned for
source code generation</h3>
<p>The downstream task of interest to us in this paper is <em>code
generation</em>, where the input to the model is a mixture of natural
language comments and code snippets, and the output is new code. Unlike
other downstream tasks, a large corpus of data is available from public
code repositories such as GitHub. Code generation can be divided into
many sub-tasks, such as variable type generation, e.g. <span
class="citation" data-cites="Wei2020LambdaNetPT">J. Wei et al.
(2020)</span>, comment generation, e.g. <span class="citation"
data-cites="liu2021retrievalaugmented">Liu et al. (2021)</span>,
duplicate detection, e.g <span class="citation"
data-cites="Mou2016ConvolutionalNN">Mou et al. (2016)</span>, code
migration from one language to another e.g. <span class="citation"
data-cites="Nguyen2015DivideandConquerAF">Nguyen, Nguyen, and Nguyen
(2015)</span> etc. A recent benchmark that covers many tasks is CodeXGLUE
<span class="citation" data-cites="Lu2021CodeXGLUEAM">(Lu et al.
2021)</span>.</p>
<p>LLM technology has brought us within reach of full-solution
generation. Codex <span class="citation"
data-cites="Chen2021EvaluatingLL">(Chen, Tworek, Jun, Yuan, Ponde, et
al. 2021)</span>, a version of GPT-3 fine-tuned for code generation, can
solve on average 47/164 problems in the HumanEval code generation
benchmark, in one attempt. HumanEval is a set of 164 hand-written
programming problems, which include a function signature, docstring,
body, and several unit tests, with an average of 7.7 tests per problem.
Smaller models have followed Codex, like GPT-J<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>
(fine-tuned on top of GPT-2), CodeParrot<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>
(also fine-tuned on top of GPT-2, targets Python generations), PolyCoder
<span class="citation" data-cites="Xu2022ASE">(Xu et al.
2022)</span>(GPT-2 style but trained directly on code).</p>
<p>LLMs comparable in size to Codex include AlphaCode <span
class="citation" data-cites="Li2022CompetitionLevelCG">(Y. Li, Choi,
Chung, Kushman, Schrittwieser, Leblond, Tom, et al. 2022)</span> and
PaLM-Coder <span class="citation"
data-cites="Chowdhery2022PaLMSL">(Chowdhery et al. 2022)</span>.
AlphaCode is trained directly on GitHub data and fine-tuned on coding
competition problems. It introduces a method to reduce from a large
number of potential solutions (up to millions) to a handful of
candidates (competitions permit a maximum of 10). On a dataset of 10000
programming problems, Codex solves around 3% of the problems within 5
attempts, versus AlphaCode which solves 4-7%. In competitions for which
it was fine-tuned (CodeContests) AlphaCode achieves a 34% success rate,
on par with the average human competitor.</p>
<p>Despite promising results there are known shortcomings. Models can
directly copy full solutions or key parts of the solutions from the
training data, rather than generating new code. Though developers make
efforts to clean and retain only high-quality code, there are no
guarantees of correctness and errors can be directly propagated through
generations.</p>
<p>Codex can also produce syntactically incorrect or undefined code, and
can invoke functions, variables, and attributes that are undefined or
out of scope. Moreover, Codex struggles to parse through increasingly
long and higher-level or system-level specifications which can lead to
mistakes in binding operations to variables, especially when the number
of operations and variables in the docstring is large. Various
approaches have been explored to filter out bad generations or repair
them, especially for syntax errors.</p>
<p>Consistency is another issue. There is a trade-off between
non-determinism and generation diversity. Some parameter settings can
control the diversity of generation (i.e., how diverse the different
generations for a single prompt might be), but there is no guarantee
that we will get the same generation if we run the system at different
times under the same settings. To alleviate this issue in measurements,
metrics such as <code>pass@k</code> (have a solution that passes the
tests within <span class="math inline"><em>k</em></span> tries) have
been modified to be probabilistic.</p>
<h2 data-number="4" id="sec:commercial"><span
class="header-section-number">4</span> Commercial programming tools that
use large language models</h2>
<figure>
<img src="copilot2.png" id="fig:copilot2" style="width:90.0%"
alt="Code generation with GitHub Copilot. The portion highlighted in blue has been generated by the model. Above: a pattern, extrapolated based on two examples. Below: a function body, generated from the signature and the first line. Source: copilot.github.com" />
<figcaption aria-hidden="true">Figure 2 - Code generation with GitHub Copilot. The
portion highlighted in blue has been generated by the model. Above: a
pattern, extrapolated based on two examples. Below: a function body,
generated from the signature and the first line. Source: <a
href="copilot.github.com"
class="uri">copilot.github.com</a></figcaption>
</figure>
<figure>
<img src="tabnine.png" id="fig:tabnine" style="width:70.0%"
alt="Code generation using the Tabnine editor extension. The grey text after the cursor is being suggested by the model based on the comment on the preceding line. Source: tabnine.com" />
<figcaption aria-hidden="true">Figure 3 - Code generation using the Tabnine editor
extension. The grey text after the cursor is being suggested by the
model based on the comment on the preceding line. Source: <a
href="tabnine.com" class="uri">tabnine.com</a></figcaption>
</figure>
<figure>
<img src="intellicode.png" id="fig:intellicode" style="width:90.0%"
alt="API suggestion using the Visual Studio IntelliCode feature. Source: Silver (2018)" />
<figcaption aria-hidden="true">Figure 4 - API suggestion using the Visual Studio
IntelliCode feature. Source: <span class="citation"
data-cites="silver_2018">Silver (2018)</span></figcaption>
</figure>
<p>OpenAI Codex is a version of GPT that is fine-tuned on publicly
available source code <span class="citation"
data-cites="chen2021codex">(Chen, Tworek, Jun, Yuan, Oliveira Pinto, et
al. 2021)</span>. While Codex itself is not a programmer-facing tool,
OpenAI has commercialised it in the form of an API that can be built
upon.</p>
<p>The principal commercial implementation of Codex thus far has been in
Github Copilot.<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> Copilot is an extension that can be
installed into code editors such as Neovim, Jetbrains, and Visual Studio
Code. Copilot uses Codex, drawing upon the contents of the file being
edited, related files in the project, and file paths or URLs of
repositories. When triggered, it generates code at the cursor location,
in much the same way as autocomplete.</p>
<p>To help expand developer expectations for the capabilities of Copilot
beyond the previous standard uses of autocomplete, suggested usage
idioms for Copilot include: writing a comment explaining what a function
does, and the function signature, and allowing Copilot to complete the
function body; completing boilerplate code; and defining test cases
(Figures <a href="#fig:copilot1" data-reference-type="ref"
data-reference="fig:copilot1">1</a> and <a href="#fig:copilot2"
data-reference-type="ref" data-reference="fig:copilot2">2</a>).
Programmers can cycle between different generations from the model, and
once a particular completion has been accepted it can be edited like any
other code.</p>
<p>As of 23 June 2022, Amazon has announced a Copilot-like feature
called CodeWhisperer,<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> which also applies a large language
model trained on a corpus of source code to generate autocompletions
based on comments and code. The marketing material describes a set of
safety features, such as: detecting when generated code is similar to
code in the training set, detecting known security vulnerabilities in
the generated code, and <em>“removing code that may be considered biased
and unfair”</em> (although this latter claim induces skepticism). At
present CodeWhisperer is not widely available and thus little is known
of its use in practice.</p>
<p>Other commercial implementations of AI-assisted autocompletion
features include Visual Studio Intellicode <span class="citation"
data-cites="silver_2018">(Silver 2018)</span> (Figure <a
href="#fig:intellicode" data-reference-type="ref"
data-reference="fig:intellicode">4</a>) and Tabnine (Figure <a
href="#fig:tabnine" data-reference-type="ref"
data-reference="fig:tabnine">3</a>)<a href="#fn7" class="footnote-ref"
id="fnref7" role="doc-noteref"><sup>7</sup></a>. These are more limited
in scope than Copilot and their user experience is commensurable to that
of using ‘traditional’ autocomplete, i.e., autocomplete that is driven
by static analysis, syntax, and heuristics.<a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.The
structure of the machine learning model used by these implementations is
not publicly disclosed; however, both rely on models that have been
trained on large corpora of publicly available source code.</p>
<p>It is interesting to note, that despite the wide variety of types of
intelligent programmer assistance we have discussed in Section <a
href="#sec:prior_models" data-reference-type="ref"
data-reference="sec:prior_models">2</a> for several aspects of
programming (authoring, transcription, modification, debugging, and
learning), commercial implementations of assistance based on large
language models thus far are aimed primarily at authoring. Authoring can
be viewed as the first natural application of a generative language
model, but the programming knowledge in these models can of course be
used for assisting programmers in other activities, too.</p>
<h2 data-number="5" id="sec:reliability"><span
class="header-section-number">5</span> Reliability, safety, and security
implications of code-generating AI models</h2>
<p>AI models that generate code present significant challenges to issues
related to reliability, safety, and security. Since the output of the
model can be a complex software artifact, determining if the output is
“correct” needs a much more nuanced evaluation than simple
classification tasks. Humans have trouble evaluating the quality of
software, and practices such as code review, applying static and dynamic
analysis techniques, etc., have proven necessary to ensure good quality
of human-written code. Current methods for evaluating the quality of
AI-generated code, as embodied in benchmarks such as HumanEval <span
class="citation" data-cites="chen2021codex">(Chen, Tworek, Jun, Yuan,
Oliveira Pinto, et al. 2021)</span>, MBPP <span class="citation"
data-cites="austin2021mbpp">(Austin et al. 2021)</span>, and
CodeContests <span class="citation" data-cites="li2022:alphacode">(Y.
Li, Choi, Chung, Kushman, Schrittwieser, Leblond, Eccles, et al.
2022)</span>, determine functional correctness of entire functions based
on a set of unit tests. Such evaluation approaches fail to consider
issues of code readability, completeness, or the presence of potential
errors that software developers constantly struggle to overcome.</p>
<p>Previous work <span class="citation"
data-cites="chen2021codex">(Chen, Tworek, Jun, Yuan, Oliveira Pinto, et
al. 2021)</span> explores numerous implications of AI models that
generate code, including issues of over-reliance, misalignment (the
mismatch between what the user prompt requests and what the user really
wants), bias, economic impact, and security implications. While these
topics each are extensive and important, due to space limitations we
only briefly mention them here and point to additional related work when
possible. Over-reliance occurs when individuals make optimistic
assumptions about the correctness of the output of an AI model, leading
to harm. For code generating models, users may assume the code is
correct, has no security vulnerabilities, etc. and those assumptions may
lead to lower quality or insecure code being written and deployed.
Existing deployments of AI models for code, such as GitHub Copilot <span
class="citation" data-cites="ziegler_2021">(Ziegler 2021)</span>, have
documentation that stresses the need to carefully review, test, and vet
generated code just as a developer would vet code from any external
source. It remains to be seen if over-reliance issues related to AI code
generation will result in new software quality challenges.</p>
<p>Since AI that generates code is trained on large public repositories,
there is potential for low-quality training data to influence models to
suggest low-quality code or code that contains security vulnerabilities.
One early study of GitHub Copilot <span class="citation"
data-cites="pearce2021copilotsecurity">(Pearce et al. 2021)</span>
examines whether code suggestions may contain known security
vulnerabilities in a range of scenarios and finds cases where insecure
code is generated. Beyond carefully screening new code using existing
static and dynamic tools that detect security vulnerabilities in
human-generated code, there are also possible mitigations that can
reduce the likelihood that the model will make such suggestions. These
include improving the overall quality of the training data by removing
low-quality repositories, and fine-tuning the large-language model
specifically to reduce the output of known insecure patterns.</p>
<h2 data-number="6" id="sec:prior_studies"><span
class="header-section-number">6</span> Usability and design studies of
AI-assisted programming</h2>
<p><span class="citation"
data-cites="vaithilingam2022expectation">Vaithilingam, Zhang, and
Glassman (2022)</span> conducted a within-subjects comparative study
(n=24) of Github Copilot, comparing its user experience to that of
traditional autocomplete (specifically, the <em>Intellisense</em>
plugin, not the same as the <em>Intellicode</em> feature mentioned
previously). Participants failed to complete the tasks more often with
Copilot than with Intellisense, and there was no significant effect on
task completion time. Perhaps unsurprisingly, the authors find that
assessing the correctness of generated code is difficult and an
efficiency bottleneck, particularly when the code generated has a
fundamental flaw or inefficiency that leads the programmer on an
ultimately unsuccessful ‘wild goose chase’ of repair or debugging.
However, the overwhelming majority (19 of 24) of participants reported a
strong preference for Copilot in a post-task survey. While participants
were less confident about the code generated by Copilot, they almost
universally (23 of 24) perceived it as more helpful, because it had the
potential for generating useful starting points and saving the
programmer the effort of searching online for documented solutions that
could be the basis for reuse.</p>
<p><span class="citation" data-cites="ziegler2022productivity">Ziegler
et al. (2022)</span> conducted a survey (n=2,047) of the perceived
productivity of Copilot users in the USA. They matched these to
telemetric usage measurements of the Copilot add-in, which included
metrics such as how often an auto-completion was shown, how often it was
accepted, how often it persisted unchanged in the document for a certain
time period, how often it persisted with minor variations (e.g.,
measured by Levenshtein distance) and so on. They find that the
acceptance rate (the ratio of accepted suggestions to shown suggestions)
is the strongest predictor of users’ perceived productivity due to
Copilot. Fascinatingly, they find that the pattern of acceptance rates
for all users in aggregate follows a daily and weekly “circadian”
rhythm, such that users are more likely to accept Copilot completions
out of working-hours and on weekends. However, for any given user, the
acceptance rate depends on that user’s normal working hours; suggestions
outside of normal working hours are less likely to be accepted. Future
work is needed to see whether this finding replicates, and if so to
establish how and why acceptance rates are so significantly affected by
working hours.</p>
<p><span class="citation" data-cites="xu2022ide">Frank F. Xu, Vasilescu,
and Neubig (2022)</span> conducted a within-subjects study (n=31)
comparing the programming experience with and without a code generation
plugin. Their experimental plugin takes the form of a text field in
which the user enters a natural language prompt, the system responds
with a list of code snippets, and when clicked the desired snippet is
inserted at the cursor. This workflow differs from Copilot’s, where the
‘prompt’ is text within the source file, and can contain a mix of
natural language comments and code. The plugin supported both code
generation (using a tree-based neural network) and code snippet
retrieval (searching the programming forum Stack Overflow). Results from
both generation and retrieval are shown in the same list, but visually
demarcated. The authors found no significant effect of the plugin on
task completion time or program correctness. They found that simple
queries were more likely to be answered correctly through generation,
and more complex queries requiring multiple steps were more likely to be
answered correctly though retrieval, and that it was possible to predict
which approach would succeed based on the word content of the queries.
Further, they found that most (60%) natural language queries that
participants wrote in their experiment were not sufficiently
well-specified for a human expert to write code implementing those
intents. Retrieved snippets were edited more often than generated
snippets, mostly to rename identifiers and choose different parameters.
In a post-experiment survey, participants reported mostly feeling
neutral or somewhat positive (30 of 31). These participants felt that
the plugin was helpful for finding snippets they were aware of but
cannot recall, and less disruptive than using a browser, but the
interaction worked better when the developer had a pre-existing
knowledge of the target APIs and frameworks, and it took experimentation
to understand the “correct way” to formulate queries. There was no clear
indication of preference between retrieval and generation.</p>
<p><span class="citation" data-cites="jiang2022discovering">Jiang et
al. (2022)</span> developed an LLM-based tool for converting natural
language statements to code. As in <span class="citation"
data-cites="xu2022ide">Frank F. Xu, Vasilescu, and Neubig (2022)</span>,
prompts are entered in a pop-up dialog invoked at the cursor from within
a code editor, rather than as comments. In a study <span
class="math inline">(<em>n</em>=14)</span>, participants were given a
week to complete two website-building tasks with the tool, while
recording the screen, and were interviewed afterwards. As in other
studies, participants saw utility in the tool for facilitating quick API
lookups and for writing boilerplate code. They found that novice
programmers’ queries were mainly natural language, whereas experts were
more likely to mix code into their requests. While some queries were
abstract, and expressed high-level goals, most had low granularity,
being “roughly equivalent to a line of code”. To cope with model
failures, participants used a variety of strategies to reword their
query, such as reducing the scope of the request or replacing words with
alternatives, but no particular strategy was observed to be more
effective than any other. Participants struggled with forming a mental
model of what the model can understand and the “syntax” of the language
it required – this is precisely the <em>fuzzy abstraction matching</em>
problem we described earlier, which the authors call an “uncanny
valley”. The authors suggest possible solutions such as automated
rewording of prompts, suggesting simpler tasks, suggesting task
breakdowns, and better onboarding and tutorials.</p>
<p><span class="citation" data-cites="barke2022grounded">Barke, James,
and Polikarpova (2022)</span> studied how programmers (<span
class="math inline"><em>n</em> = 20</span>) use GitHub Copilot to
complete short programming tasks in Python, Rust, Haskell, and Java.
Through analysis of screen recordings, the authors identifed two primary
modes of interaction with Copilot: <em>acceleration</em>, where the
programmer has a well-formed intent and Copilot speeds up code authoring
in “small logical units”, and <em>exploration</em>, where Copilot
suggestions are used to assist the planning process, “help them get
started, suggest potentially useful structure and API calls, or explore
alternative solutions”. In acceleration, long code suggestions, which
take time to read and evaluate, can break the programmer’s flow.
Participants developed heuristics for quickly scanning suggestions, such
as looking for the presence of certain keywords. In exploration,
participants were more likely to prompt using purely natural language
comments, rather than a mix of comments and code. Moreover, these prompt
comments were often ‘cleaned’ subsequent to accepting a suggestion,
which implies a form of ‘instruction language’ that is separate from
‘explanation language’.</p>
<p><span class="citation" data-cites="madi2022readable">Madi
(2022)</span> compared the readability of code generated by Copilot with
that of code written by human programmers in a user study (<span
class="math inline"><em>n</em> = 21</span>). They found that model
generated code is comparable in complexity and readability to
human-authored code.</p>
<figure>
  <img src="bing_developer_assistant.png" id="fig:bing_developer_assistant"
  alt="Searching for code snippets using Bing Developer Assistant. A result for
  Stack Overflow is shown. Note how the query “generate md5 hash from string
  @line” contains a hint about the identifier line, which is used to rewrite the retrieved
  snippet. Source: https://www.microsoft.com/en-us/research/publication/
  building-bing-developer-assistant/" />
  <figcaption aria-hidden="true">Figure 5 - Searching for code snippets using Bing Developer Assistant. A result for
    Stack Overflow is shown. Note how the query “generate md5 hash from string
    @line” contains a hint about the identifier line, which is used to rewrite the retrieved
    snippet. Source:
  <a href="https://www.microsoft.com/en-us/research/publication/building-bing-developer-assistant/"
  class="uri">https://www.microsoft.com/en-us/research/publication/building-bing-developer-assistant/</a></figcaption>
</figure>
<p>The Bing Developer Assistant <span class="citation"
data-cites="wei2015building zhang2016bing">(Y. Wei et al. 2015; Zhang et
al. 2016)</span> (also referred to as Bing Code Search) was an
experimental extension for Visual Studio initially released in 2015. It
enabled an in-IDE, identifier-aware search for code snippets from forums
such as Stack Overflow. It had the ability to rewrite retrieved code to
use identifiers from the programmer’s current file. A user study (n=14)
comparing task time in performing 45 short programming tasks with the
extension versus regular web search found on average 28% of time was
saved with the extension. Morever telemetry data gathered over three
weeks (representing around 20,000 users and around 3,000 queries per
day) showed that several programmers used the feature frequently. Some
used it repeatedly for related problems in quick succession, showing its
use in multi-step problems. Others issued the same query multiple times
on separate days, suggesting that the speed of auto-completion was
useful even if the programmer knew the solution.</p>
<h2 data-number="7" id="sec:experience_reports"><span
class="header-section-number">7</span> Experience reports</h2>
<p>At present, there is not a lot of research on the user experience of
programming with large language models beyond the studies we have
summarised in Section <a href="#sec:prior_studies"
data-reference-type="ref" data-reference="sec:prior_studies">6</a>.
However, as the availability of such tools increases, professional
programmers will gain long-term experience in their use. Many such
programmers write about their experiences on personal blogs, which are
then discussed in online communities such as Hacker News. Inspired by
the potential for these sources to provide rich qualitative data, as
pointed out by Barik <span class="citation"
data-cites="barik2015heart sarkar2022lambdas">(Barik, Johnson, and
Murphy-Hill 2015; Sarkar et al. 2022)</span>, we draw upon a few such
experience reports. A full list of sources is provided Appendix <a
href="#apx:experience_report_sources" data-reference-type="ref"
data-reference="apx:experience_report_sources">11</a>; below we
summarise their key points.</p>
<h3 data-number="7.1" id="writing-effective-prompts-is-hard"><span
class="header-section-number">7.1</span> Writing effective prompts is
hard</h3>
<p>As with several other applications of generative models, a key issue
is the writing of prompts that increase the likelihood of successful
code generation. The mapping that these models learn between natural
language and code is very poorly understood. Through experimentation,
some have developed heuristics for prompts that improve the quality of
the code generated by the model. One developer, after building several
applications and games with OpenAI’s <code>code-davinci</code> model
(the second generation Codex model), advises to <em>“number your
instructions”</em> and creating <em>“logic first”</em> before UI
elements. Another, in using Copilot to build a classifier for natural
language statements, suggests to provide <em>“more detail”</em> in
response to a failure to generate correct code. For example, when asking
Copilot to <em>“binarize”</em> an array fails, they re-write the prompt
to <em>“turn it into an array where [the first value] is 1 and [the
second value] is 0”</em> – effectively pseudocode – which generates a
correct result.</p>
<p>Commenters on Hacker News are divided on the merits of efforts
invested in developing techniques for prompting. While some see it as a
new level of abstraction for programming, others see it as indirectly
approaching more fundamental issues that ought to be solved with better
tooling, documentation, and language design:</p>
<p><em>“You’re not coding directly in the language, but now you’re
coding in an implicit language provided by Copilot. [...] all it really
points out is that code documentation and discovery is terrible. But I’m
not for sure writing implicit code in comments is really a better
approach than seeking ways to make discovery of language and library
features more discoverable.”</em></p>
<p><em>“[...] the comments used to generate the code via GitHub Copilot
are just another very inefficient programming language.”</em></p>
<p><em>“[Responding to above] There is nonetheless something extremely
valuable about being able to write at different levels of abstraction
when developing code. Copilot lets you do that in a way that is way
beyond what a normal programming language would let you do, which of
course has its own, very rigid, abstractions. For some parts of the code
you’ll want to dive in and write every single line in painstaking
detail. For others [...] [Copilot] is maybe enough for your purposes.
And being able to have that ability, even if you think of it as just
another programming language in itself, is huge.”</em></p>
<p>Being indiscriminately trained on a corpus containing code of varying
ages and (subjective) quality has drawbacks; developers encounter
generated code which is technically correct, but contains practices
considered poor such as unrolled loops and hardcoded constants. One
Copilot user found that:</p>
<p><em>“Copilot [...] has made my code more verbose. Lines of code can
be liabilities. Longer files to parse, and more instances to refactor.
Before, where I might have tried to consolidate an API surface, I find
myself maintaining [multiple instances].”</em></p>
<p>Another Copilot user reflected on their experience of trying to
generate code that uses the <code>fastai</code> API, which frequently
changes:</p>
<p><em>“[...] since the latest version of fastai was only released in
August 2020, GitHub Copilot was not able to provide any relevant
suggestions and instead provided code for using older versions of
fastai. [...] To me, this is a major concern [...] If we are using
cutting edge tools [...] Copilot has no knowledge of this and cannot
provide useful suggestions.”</em></p>
<p>On the other hand, developers can also be exposed to <em>better</em>
practices and APIs through these models. The developer that found
Copilot to make their code more verbose also observed that:</p>
<p><em>“Copilot gives structure to Go errors . [...] A common idiom is
to wrap your errors with a context string [which can be written in an
inconsistent, ad-hoc style] [...] Since using Copilot, I haven’t written
a single one of these error handling lines manually. On top of that, the
suggestions follow a reasonable structure where I didn’t know structure
had existed before. Copilot showed me how to add structure in my code in
unlikely places. For writing SQL, it helped me write those annoying
foreign key names in a consistent format [...]</em></p>
<p>[Additionally,] One of the more surprising features has been [that]
[...] I find myself discovering new API methods, either higher-level
ones or ones that are better for my use case.”</p>
<p>In order to discover new APIs, of course, the APIs themselves need to
be well-designed. Indeed, in some cases the spectacular utility of large
language models can be largely attributed to the fact that API designers
have already done the hard work of creating an abstraction that is a
good fit for real use cases <span class="citation"
data-cites="myers2016improving piccioni2013empirical macvean2016api">(Myers
and Stylos 2016; Piccioni, Furia, and Meyer 2013; Macvean et al.
2016)</span>. As a developer who used Copilot to develop a sentiment
classifier for Twitter posts matching certain keywords remarks,
<em>“These kinds of things are possible not just because of co pilot
[sic] but also because we have awesome libraries which have abstracted a
lot of tough stuff.”</em> This suggests that API design, not just for
human developers but also as a target for large language models, will be
important in the near and mid-term future.</p>
<p>Moreover, breaking down a prompt at the ‘correct’ level of detail is
also emerging as an important developer skill. This requires at least
some familiarity, or a good intuition, for the APIs available. Breaking
down prompts into steps so detailed that the programmer is effectively
writing pseudocode, can be viewed as an anti-pattern, and can give rise
to the objections cited earlier that programming via large language
models is simply a <em>“very inefficient programming language”</em>. We
term this the problem of <em>fuzzy abstraction matching</em>. The
problem of figuring out what the system can and can’t do, and matching
one’s intent and instructions with the capabilities of the system, is
not new – it has been well-documented in natural language interaction
<span class="citation" data-cites="mu2019we luger2016like">(Mu and
Sarkar 2019; Luger and Sellen 2016)</span>. It is also observed in
programming notation design as the ‘match-mismatch’ hypothesis <span
class="citation" data-cites="green1992visual chalhoub2022freedom">(T. R.
Green and Petre 1992; Chalhoub and Sarkar 2022)</span>. In the broadest
sense, these can be seen as special cases of Norman’s “gulf of
execution” <span class="citation"
data-cites="DBLP:journals/hhci/HutchinsHN85">(Hutchins, Hollan, and
Norman 1985)</span>, perhaps the central disciplinary problem of first
and second-wave <span class="citation"
data-cites="DBLP:journals/interactions/Bodker15">(Bødker 2015)</span>
human-computer interaction research: ‘how do I get the computer to do
what I want it to do?’.</p>
<p>What distinguishes fuzzy abstraction matching from previous
incarnations of this problem is the resilience to, and accommodation of,
various levels of abstraction afforded by large language models. In
previous natural language interfaces, or programming languages, the user
needed to form an extremely specific mental model before they could
express their ideas in machine terms. In contrast, large language models
can generate plausible and correct results for statements at an
extremely wide range of abstraction. In the context of programming
assistance, this can range from asking the model to write programs based
on vague and underspecified statements, requiring domain knowledge to
solve, through to extremely specific and detailed instructions that are
effectively pseudocode. This flexibility is ultimately a double-edged
sword: it has a lower floor for users to start getting usable results,
but a higher ceiling for getting users to maximum productivity.</p>
<p>In the context of programming activities, <em>exploratory
programming</em>, where the goal is unknown or ill-defined <span
class="citation" data-cites="kery2017exploring sarkar2016phd">(Kery and
Myers 2017; Sarkar 2016)</span>, does not fit the framing of fuzzy
abstraction matching (or indeed any of the variations of the gulf of
execution problem). When the very notion of a crystallised user
<em>intent</em> is questioned, or when the design objective is for the
system to influence the intent of the user (as with much designerly and
third-wave HCI work), the fundamental interaction questions change. One
obvious role the system can play in these scenarios is to help users
refine their own concepts <span class="citation"
data-cites="kulesza2014structured">(Kulesza et al. 2014)</span> and
decide what avenues to explore. Beyond noting that such activities
exist, and fall outside the framework we have proposed here, we will not
explore them in greater detail in this paper.</p>
<h3 data-number="7.2"
id="the-activity-of-programming-shifts-towards-checking-and-unfamiliar-debugging"><span
class="header-section-number">7.2</span> The activity of programming
shifts towards checking and unfamiliar debugging</h3>
<p>When code can be generated quickly, as observed with the studies in
Section <a href="#sec:prior_studies" data-reference-type="ref"
data-reference="sec:prior_studies">6</a>, checking the correctness of
generating code becomes a major bottleneck. This shift, or tradeoff, of
faster authoring at the expense of greater time spent checking code, is
not without criticism. For some it is the wrong balance of priorities
between system and programmer.</p>
<p>Correspondingly, some users have developed heuristics for when the
cost of evaluating the correctness of the code is greater than the time
or effort saved by code generation, such as to focus on very short
(e.g., single line) completions and ignore longer completions.</p>
<p>Furthermore, some users have found that rather than having
suggestions show all the time, which can be distracting and time
consuming, more intentional use can be made of Copilot by switching off
auto-suggestion and only triggering code completion manually using a
keyboard shortcut. However, this requires users to form a mental model
of when Copilot is likely to help them in their workflow. This mental
model takes time and intentionality to build, and may be incorrect.
Moreover, it introduces a new cognitive burden of constantly evaluating
whether the current situation would benefit from LLM assistance.
Commenters on Hacker News raise these issues:</p>
<p><em>“I find I spend my time reviewing Copilot suggestions (which are
mostly wrong) rather than thinking about code and actually doing the
work.”</em></p>
<p><em>“[...] It’s much quicker to read code than to write it. In
addition, 95% of Copilots suggestions are a single line and they’re
almost always right (and also totally optional).[...] I admit that I’m
paranoid every time it suggests more than 2 lines so I usually avoid it.
[...] I’ve run into Copilot induced headaches twice. Once was in the
first week or so of using it. I sweared off [sic] of using it for
anything more than a line then. Eventually I started to ease up since it
was accurate so often and then I learned my second lesson with another
mistake. [...]”</em></p>
<p><em>“[...] writing code is not the bottleneck in need of
optimization. Conceiving the solution is. Any time “saved” through
Copilot and it’s ilk is immediately nullified by having to check it’s
correctness. [...]”</em></p>
<p><em>“What I want is a copilot that finds errors [...] Invert the
relationship. I don’t need some boilerplate generator, I need a
nitpicker that’s smarter than a linter. I’m the smart thinker with a
biological brain that is inattentive at times. Why is the computer
trying to code and leaving mistake catching to me? It’s
backwards.”</em></p>
<p><em>“I turned off auto-suggest and that made a huge difference. Now
I’ll use it when I know I’m doing something repetitive that it’ll get
easily, or if I’m not 100% sure what I want to do and I’m curious what
it suggests. This way I get the help without having it interrupt my
thoughts with its suggestions.”</em></p>
<p>Another frequent experience is that language models can introduce
subtle, difficult to detect bugs, which are not the kind that would be
introduced by a human programmer writing code manually. Thus, existing
developer intuitions around the sources of errors in programs can be
less useful, or even misleading, when checking the correctness of
generated code.</p>
<p>One developer reported their experience of having an incorrect, but
plausible-sounding field name suggested by Copilot
(<code>accessTokenSecret</code> instead of <code>accessSecret</code>)
and the consequent wild goose chase of debugging before discovering the
problem. As sources of error, these tools are new, and developers need
to learn new craft practices for debugging. <em>“There are zero places
that can teach you those things. You must experience them and unlock
that kind of knowledge.”</em>, the developer concludes, <em>“Don’t let
code completion AI tools rule your work. [...] I don’t blame [Copilot]
for this. I blame myself. But whatever. At least I got some
experience.”</em>. Commenters on Hacker News report similar
experiences:</p>
<p><em>“[...] The biggest problem I’ve had is not that it doesn’t write
correctly, it’s that it think it knows how and then produce good looking
code at a glance but with wrong logic. [...]”</em></p>
<p><em>“[...] it has proved to be very good at producing superficially
appealing output that can stand up not only to a quick scan, but to a
moderately deep reading, but still falls apart on a more careful
reading. [...] it’s an uncanny valley type effect. [...] it’s almost the
most dangerous possible iteration of it, where it’s good enough to fool
a human functioning at anything other than the highest level of
attentiveness but not good enough to be correct all the time. See also,
the dangers of almost self-driving cars; either be self-driving or don’t
but don’t expect halfway in between to work well.”</em></p>
<p><em>“[...] The code it generates _looks_ right but is usually wrong
in really difficult to spot ways but things you’d never write
yourself.”</em></p>
<p>Many developers reported concerns around such tools repeating private
information, or repeating copyrighted code verbatim, which might have
implications for the licenses in their own projects. Notions of the
dangers of such “stochastic parrots” <span class="citation"
data-cites="DBLP:conf/fat/BenderGMS21">(Bender et al. 2021)</span> are
not new and have been well-explored, and are not as directly connected
to the user experience of programming assistance as some of the other
concerns we have listed here. As such, we will not enter that discussion
in depth here, except to mention that these concerns were present in
several blog articles and online discussions.</p>
<p>Thus, in practice, programmers describe the challenges of writing
effective prompts, misinterpreted intent, code that includes subtle bugs
or poor programming practices, the burden of inspecting and checking
that generated code is correct, and worries about private information,
plagiarism and copyright.</p>
<h3 data-number="7.3"
id="these-tools-are-useful-for-boilerplate-and-code-reuse"><span
class="header-section-number">7.3</span> These tools are useful for
boilerplate and code reuse</h3>
<p>Despite the challenges we have described so far in this section, the
utility of these tools in certain contexts is undeniable, and some
programmers report having developed workflows, in certain contexts, that
are heavily dependent on AI assistance. Particularly for simple tasks
that require a lot of “boilerplate” code, or common tasks for which
there are likely to be snippets of code online which prior to these AI
assistants would have required a web search to retrieve. Hacker News
commenters write:</p>
<p><em>“These days not having Copilot is a pretty big productivity hit
to me. The other day Copilot somehow stopped offering completions for
maybe an hour, and I was pretty shocked to realize how much I’ve grown
to rely on just hitting tab to complete the whole line. (I was writing
Go at the time which is on the boilerplatey side among the mainstream
languages, so Copilot is particularly effective [...]”</em></p>
<p><em>“I use GTP-3 codex [sic] daily when working. It saves me time,
helps me explore unfamiliar languages and APIs and generates approaches
to solve problems. It can be shockingly good at coding in narrow
contexts. It would be a mistake to miss the developments happening in
this area”</em></p>
<p><em>“[...] for a lot of quick programming questions, I’m finding I
don’t even need a search engine. I just use Github Copilot. For example,
if I wanted to remember how to throw an exception I’d just write that as
a comment and let Copilot fill in the syntax. Between that and official
docs, don’t need a ton else.”</em></p>
<p><em>“[...] It’s changing the way I write code in a way that I can
already tell is allowing me to be much lazier than I’ve previously been
about learning various details of languages and libraries.
[...]”</em></p>
<p><em>“[...] Github Copilot [...] pretty much replaced almost my entire
usage of Stack Overflow.[...]”</em></p>
<p><em>“[...] GitHub Copilot really shines in rote work: when it can
correctly infer what you are about to do, it can and will assist you
correctly. It’s not able to make big decisions, but in a pinch, it might
be able to give hints. [...] If used right, Copilot can give developers
a significant velocity boost, especially in greenfield projects where
there is lots and lots of boilerplate to write. [...]”</em></p>
<h2 data-number="8" id="sec:metaphors"><span
class="header-section-number">8</span> The inadequacy of existing
metaphors for AI-assisted programming</h2>
<h3 data-number="8.1" id="ai-assistance-as-search"><span
class="header-section-number">8.1</span> AI assistance as search</h3>
<p>In research studies, as well as in reports of developer experiences,
comparisons have been drawn between the nature of AI programming
assistance and programming by searching and reusing code from the
Internet (or from institutional repositories, or from the same project,
or from a developer’s previous projects).</p>
<p>The comparison between AI programming assistance and search is a
natural one, and there are many similarities. Superficially, both have a
similar starting point: a <em>prompt</em> or query that is predominantly
natural language (but which may also contain code snippets). From the
user perspective, both have an <em>information asymmetry</em>: the user
does not know precisely what form the result will take. With both search
and AI assistance, for any given query, there will be <em>several
results</em>, and the user will need to invest time evaluating and
comparing them. In both cases, the user may only get an <em>inexact
solution</em>, or indeed nothing like what they want, and the user may
need to invest time adapting and repairing what they get.</p>
<p>However, there are differences. When searching the web, programmers
encounter not just code, but a variety of types of results intermingled
and enmeshed. These include code snippets interspersed with human
commentary, perhaps discussions on forums such as Stack Overflow,
videos, and images. A search may return new APIs or libraries related to
the query, thus showing results at different levels of abstraction.
Search has signals of provenance: it is often (though not always)
possible to determine the source of a code snippet on the web. There is
a lot of information scent priming to assist with the information
foraging task <span class="citation"
data-cites="srinivasa2016foraging">(Srinivasa Ragavan et al.
2016)</span>. In this way, programming with search is a <em>mixed
media</em> experience.</p>
<p>In contrast, programming with large language models can be said to be
a <em>fixed media</em> experience. The only output is tokens (code,
comments, and data) that can be represented within the context of the
code editor. This has some advantages: the increased speed of code
insertion (which is the immediate aim) often came up in experience
reports. However, the learning, exploration, and discovery, and access
to a wide variety of sources and media types that occurs in web search
is lost. Provenance, too is lost: it is difficult to determine whether
the generation is original to the model, or a stochastic parroting <span
class="citation"
data-cites="DBLP:conf/fat/BenderGMS21 ziegler_2021">(Bender et al. 2021;
Ziegler 2021)</span>. Moreover, due to privacy, security, and
intellectual property concerns, the provenance of code generated by
large language models may be withheld or even destroyed <span
class="citation" data-cites="sarkar2022explainable">(Sarkar
2022)</span>. This suggests that in future assistance experiences,
mixed-media search might be integrated into programmer assistance tools,
or the models themselves might be made capable of generating more types
of results than the simple code autocomplete paradigm of current
tools.</p>
<h3 data-number="8.2" id="ai-assistance-as-compilation"><span
class="header-section-number">8.2</span> AI assistance as
compilation</h3>
<p>An alternative perspective is that AI assistance is more like a
compiler. In this view, programming through natural language prompts and
queries is a form of higher-level specification, that is ‘compiled’ via
the model to the source code in the target language, which is lower
level.</p>
<p>Let us (crudely) assume that as programming notations travel along
the abstraction continuum from ‘lower’ to ‘higher’ levels, the
programmer becomes, firstly, less concerned with the mechanistic details
of program execution, and secondly, more and more declarative,
specifying <em>what</em> computation is required rather than
<em>how</em> to compute it. In general, these are desirable properties
of programming notations, but they do not always make the activity of
programming easier or more accessible. As people who write code in
declarative languages or formal verification tools will tell you, it’s
often much more difficult to specify the <em>what</em> than the
<em>how</em>. The much more broadly adopted practice of test-driven
development is adjacent; while tests are not necessarily written in a
higher-level language than the code, they aim to capture a higher-level
notion of correctness, the <em>what</em> of the problem being solved.
Learning to be a test engineer takes time and experience, and the entire
distinct career path of “software engineer in test” attests to the
specialised requirements of programming at higher levels of
abstraction.</p>
<p>Some would draw a distinction between programming in a specification
language and a compiled programming language. Tony Hoare himself
considers these different, on the grounds that while a compiler only
aims to map a program from the source language into a finite set of
valid programs in the target language, a specification might be
satisfied by an infinite number of valid programs (<em>pers comm.</em>,
first author, ca. 2014). Thus the technical and interaction design
problems of programming through specification refinement encompasses,
but is much broader than, the technical and interaction design problems
of compilers. While we acknowledge this distinction, there is
insufficient empirical evidence from the experience reports summarised
in Section <a href="#sec:experience_reports" data-reference-type="ref"
data-reference="sec:experience_reports">7</a> that working programmers
themselves consistently make a meaningful distinction between these
concepts.</p>
<p>Programming with large language models, like in a higher-level
notation, also allows the programmer to be less concerned with details
of the target language. For example, developers in our experience
reports relied on AI assistance to fill in the correct syntax, or to
discover and correctly use the appropriate API call, thus allowing them
to focus on higher-level aspects of the problem being solved. However,
there are fundamental differences between this experience and the
experience of using a compiler. First, the abstraction is not complete,
i.e., a programmer cannot <em>completely</em> be unaware of the target
language, they must still be able to understand and evaluate the
generated code in order to use such tools effectively. With compilers,
although knowledge of the target language can help experienced
developers in certain circumstances, it is far from a prerequisite for
effective usage. Moreover, compilers can be relied on almost universally
to generate a correct and complete translation from source to target
language, whereas programming with AI assistance involves the active
checking and adaptation of translated code. Next, compilers are
(comparatively) deterministic, in that they consistently produce the
same output for the same input, but this is not the case for current AI
programming tools (although this is not a fundamental limitation, and
consistency can be enforced). Finally, though they are often criticised
for being cryptic and unhelpful <span class="citation"
data-cites="barik2018should">(Barik et al. 2018)</span>, compilers do
offer levels of interaction and feedback through warnings and error
messages, which help the programmer improve the code in the source
language; there is currently no such facility with AI programming tools
and this strikes us as an area with potential for innovation.</p>
<p>Perhaps more profoundly, while natural language can be used to
express concepts at a higher abstraction level, the <em>range</em> of
abstraction expressible in natural language is much wider than with
other forms of programming notation. Traditional programming notations
with ad-hoc abstraction capabilities (subroutines, classes, etc.) allow
programmers to manually raise the level of abstraction of their own code
and APIs. But with code generated by language models, as we have seen
from the reports in Section <a href="#sec:experience_reports"
data-reference-type="ref" data-reference="sec:experience_reports">7</a>,
a prompt can span the gamut from describing an entire application in a
few sentences, to painstakingly describing an algorithm in step-by-step
pseudocode. Thus it would be a mistake to view programming with AI
assistance as another rung on the abstraction ladder. Rather, it can be
viewed as a device that can teleport the programmer to arbitrary rungs
of the ladder as desired.</p>
<p>We close the discussion on AI assistance as a compiler with a few
miscellaneous notes. The idea of using natural language as a programming
notation has a long history (e.g., <span class="citation"
data-cites="miller1981natural lieberman2006feasibility">(Miller 1981;
Lieberman and Liu 2006)</span>), which we will not cover here. However,
it is notable that there are many ways that natural language has been
integrated with programming, such as debugging <span class="citation"
data-cites="ko2004designing">(Ko and Myers 2004)</span>. With large
language models, there are better capabilities for inference of intent
and translation to code, but therefore also the potential to open up new
strategies for inspecting and explaining code. There are also new
failure modes for this paradigm of programming.</p>
<h3 data-number="8.3" id="ai-assistance-as-pair-programming"><span
class="header-section-number">8.3</span> AI assistance as pair
programming</h3>
<p>The third common perspective is that AI-assisted programming is like
pair programming. GitHub Copilot’s commercial tagline describes it as
“your AI pair programmer”. As opposed to search and compilation, which
are both relatively impersonal tools, the analogy with pair programming
is evocative of a more bespoke experience; assistance from a partner
that understands more about your specific context and what you’re trying
to achieve. AI-assisted programming does have the potential to be more
personalised, to the extent that it can take into consideration your
specific source code and project files. As Hacker News commenters
write:</p>
<p><em>“[...] at one point it wrote an ENTIRE function by itself and it
was correct. [...] it wasn’t some dumb boilerplate initialization
either, it was actual logic with some loops. The context awareness with
it is off the charts sometimes.[...]”</em></p>
<p><em>“[...] It’s like having the stereotypical “intern” as an
associate built-in to your editor. [...] It’s also ridiculously
flexible. When I start writing graphs in ASCII (cause I’m just quickly
writing something down in a scratch file) it’ll actually understand what
I’m doing and start autocompleting textual nodes in that ASCII
graph.”</em></p>
<p>Besides personalisation, the analogy also recalls the conventional
role-division of pair programming between “driver” and “navigator”. When
programming, one needs to form mental models of the program at many
layers: from the specific statement being worked on, to its context in a
subroutine, to the role that subroutine plays in a module, to the module
within the program. However, code must be written at the statement
level, which forces developers to keep this lowest level constantly at
the forefront of their working memory. Experienced developers spend more
time mapping out their code so that they can spend less time writing it.
Research into code display and navigation has explored how different
ways of presenting lines of code can help programmers better keep these
different layers of mental models in mind <span class="citation"
data-cites="henley2014patchworks">(Henley and Fleming 2014)</span>. Pair
programming, the argument goes, allows two partners to share the burden
of the mental model. The driver codes at the statement and subroutine
level while the navigator maps out the approach at the module and
program level.</p>
<p>By analogy to pair programming, the AI assistant taking the role of
the driver, a solo programmer can now take the place of the navigator.
But as we have seen, the experience of programming with AI assistance
does not consistently absolve the human programmer of the responsibility
for understanding the code at the statement and subroutine level. The
programmer may be able to become <em>“lazier [...] about learning
various details of syntax and libraries”</em>, but the experience still
involves much greater statement-level checking.</p>
<p>While a pair programming session requires a conscious, negotiated
decision to swap roles, a solo programmer with an AI assistant might
find themselves fluidly traversing the spectrum from driving to
navigation, from one moment to the next. This may partially explain why,
in a preliminary experiment (n=21) comparing the experience of “pair
programming” with GitHub Copilot to programming in a human pair either
as driver or navigator, <span class="citation"
data-cites="imai2022github">(Imai 2022)</span> finds that programmers
write more lines of code with Copilot than in a human pair, but these
lines are of lower quality (more are subsequently deleted).</p>
<p>Moreover, meta-analyses of pair programming have shown mixed efficacy
of human pair programming on task time, code quality and correctness
<span class="citation"
data-cites="salge2016pair hannay2009effectiveness">(Salge and Berente
2016; Hannay et al. 2009)</span>, suggesting that emulating the pair
programming experience is not necessarily a good target to aim for.
Multiple studies have concluded that the apparent successes of pair
programming can be attributed, not to the role division into driver and
navigator, but rather the high degree of <em>verbalisation</em> that
occurs when pair programmers are forced to rationalise their decisions
to each other <span class="citation"
data-cites="hannay2009effectiveness">(Hannay et al. 2009)</span>. Others
have found that programming in pairs induces greater focus out of a
respect for shared time; pair programmers are less likely to read
emails, surf the web, or take long phone calls <span class="citation"
data-cites="williams2000all">(L. A. Williams and Kessler 2000)</span>.
These particular benefits of pair programming are not captured at all by
AI assistance tools.</p>
<p>The comparison to pair programming is thus relatively superficial,
and today’s experience of AI-assisted programming is not comparable with
pair programming to the same extent as it is with search or
compilation.</p>
<h3 data-number="8.4" id="a-distinct-way-of-programming"><span
class="header-section-number">8.4</span> A distinct way of
programming</h3>
<p>LLM-assisted programming assistance bears similarities to search:
both begin with a prompt, both have an information asymmetry, there are
several results, with inexact solutions. But there are differences:
search is mixed-media, whereas LLM assistance is fixed. Search (often)
has provenance, and language models do not.</p>
<p>It also bears similarities to compilation and programming by
specification. Both enable programming at a ‘higher’ level of
abstraction (for some definition of higher). Yet unlike with compilers,
a programmer using AI assistance must still have a working knowledge of
the target language, they must actively check the output for
correctness, and they get very little feedback for improving their
‘source’ code.</p>
<p>It also bears a superficial similarity to pair programming, in that
it promises to let the programmer take the role of ‘navigator’, forming
high-level mental models of the program while delegating the role of
‘driver’ to the language model. But unlike with pair programming, the
human navigator must often hop into the driver’s seat. And unlike with
pair programming, LLM-assisted programming does not require
verbalisation, nor does it coerce greater focus out of a respect for
shared time.</p>
<p>Thus existing metaphors do not completely capture the experience of
LLM-assisted programming. It is emerging as a distinct way of
programming. It does not quite strike us as a distinct <em>practice</em>
of programming, as that term has been applied to communities of
programmers united by similar ethos and aims, such as enterprise
software engineers, bricoleurs, live coders, and code benders; but as
<span class="citation" data-cites="bergstrom2016practices">Bergström
and Blackwell (2016)</span> note, there are no clear criteria by which we
can define the boundaries of a practice. Nor does it strike us as being
a new <em>activity</em> of programming as per the cognitive dimensions
framework, since AI assistance is clearly orthogonal to authoring,
transcription, and modification, being applicable to each of these
activities and others besides. Yet as a way of programming it seems to
affect programmer’s experience more profoundly than a feature such as
autocomplete, having far-reaching impact on their attitudes and
practices of authoring, information foraging, debugging, refactoring,
testing, documentation, code maintenance, learning, and more.</p>
<h2 data-number="9" id="sec:eup"><span
class="header-section-number">9</span> Issues with application to
end-user programming</h2>
<p>The benefits and challenges of programming with LLMs discussed so far
concern the professional programmer, or a novice programmer in training.
They have formal training in programming and, often, some understanding
of the imperfect nature of AI-generated code. But the majority of people
who program do not fall into this category. Instead, they are ordinary
end users of computers who program to an end. Such end-user programmers
often lack knowledge of programming, or the workings of AI. They also
lack the inclination to acquire those skills.</p>
<p>It is reasonable to say that such end-user programmers (e.g.,
accountants, journalists, scientists, business owners) stand to benefit
the most from AI assistance, such as LLMs. In one ideal world, an
end-user wanting to accomplish a task could do so by simply specifying
their intent in familiar natural language without prior knowledge of the
underlying programming model, or its syntax and semantics. The code will
get generated and even automatically run to produce the desired
output.</p>
<p>However, as we have seen so far, the world is not ideal and even
trained programmers face various challenges when programming with AI.
These challenges are only exacerbated for end-user programmers, as a
study by <span class="citation"
data-cites="ragavan2022gridbook">Srinivasa Ragavan et al. (2022)</span>
observes.</p>

<figure>
<img src="gridbook-addin.png" id="fig:gridbook"
alt="GridBook interface showing natural language formula in the spreadsheet grid." />
<figcaption aria-hidden="true">Figure 6 - GridBook interface showing natural language formula in the spreadsheet grid.</figcaption>
</figure>

<p>Participants in the study were data analysts (n=20) conducting
exploratory data analysis in GridBook, a natural-language augmented
spreadsheet system. In GridBook (Figure <a href="#fig:gridbook"
data-reference-type="ref"
data-reference="fig:gridbook">6</a>, adopted from <span
class="citation" data-cites="ragavan2022gridbook">(Srinivasa Ragavan et
al. 2022)</span>) users can write spreadsheet formulas using the natural
language (Figure <a href="#fig:gridbook" data-reference-type="ref"
data-reference="fig:gridbook">6</a>: a-f); a formal formula
is then synthesized from the natural language utterance. GridBook also
infers the context of an utterance; for example, in Figure <a
href="#fig:gridbook" data-reference-type="ref"
data-reference="fig:gridbook">6</a>, the query in label 4
is a follow-up from label 3. Both the natural language utterance and the
synthesized formula are persisted for users to edit and manipulate.</p>
<h3 data-number="9.1"
id="issue-1-intent-specification-problem-decomposition-and-computational-thinking"><span
class="header-section-number">9.1</span> Issue 1: Intent specification,
problem decomposition and computational thinking</h3>
<p>When attempting to accomplish data analysis tasks using natural
language, participants had to refine their specification of intent in
the natural language several times, before they arrived at the desired
result (if they did). The NL utterances were often underspecified,
ambiguous, too complex, or contained domain phrases not specified in the
context (e.g., in the data being analyzed). Thus, the first issue is to
communicate the capabilities of the system, and make it interpretable so
users can see how their prompt is being interpreted.</p>
<p>End-user programmers often lack computational thinking skills <span
class="citation" data-cites="wing2011computationalthinking">(Wing
2011)</span>, such as the ability to decompose problems into
subproblems, reformulate problems in ways that can be computed by a
system, etc. However, effective use of LLMs such as Codex requires such
skills. For example, if these models are most accurate when solutions to
a problem are single line, then the user should be able to break their
problem into smaller sub-problems each of which can be solved in one or
two lines. Moreover, they might also lack the ability to frame a problem
as generic computational problems, rather than domain-specific problems.
For example, a realtor is more likely to ask “which is the largest
house” (declaratively), instead of “which is the house with maximum
constructed area” (procedurally).</p>
<p>Therefore, end-user computing environments powered by AI should help
end-user programmers think “computationally”: they must aid users in
breaking down their problems to smaller steps, or guiding users towards
alternative strategies to specify or solve a problem (e.g., providing
examples, offering alternatives) or even seek procedural prompts where
needed (e.g., for disambiguation).</p>
<h3 data-number="9.2"
id="issue-2-code-correctness-quality-and-overconfidence"><span
class="header-section-number">9.2</span> Issue 2: Code correctness,
quality and (over)confidence</h3>
<p>The second challenge is in verifying whether the code generated by
the model is correct. In GridBook, users were able to see the natural
language utterance, synthesized formula and the result of the formula.
Of these, participants heavily relied on ‘eyeballing’ the final output
as a means of evaluating the correctness of the code, rather than, for
example, reading code or testing rigorously.</p>
<p>While this lack of rigorous testing by end-user programmers is
unsurprising, some users, particularly those with low computer
self-efficacy, might overestimate the accuracy of the AI, deepening the
overconfidence end-user programmers are known to have in their programs’
accuracy <span class="citation" data-cites="panko2008reducing">(Panko
2008)</span>. Moreover, end-user programmers might not be able to
discern the quality of non-functional aspects of the generated code,
such as security, robustness or performance issues.</p>
<h3 data-number="9.3"
id="issue-3-code-comprehension-and-maintenance"><span
class="header-section-number">9.3</span> Issue 3: Code comprehension and
maintenance</h3>
<p>A third challenge with AI-driven programming is the issue of code
comprehension. During GridBook’s user evaluation, participants mentioned
that the generated formulas are hard to understand, even when users were
familiar with the target language. This has potentially severe
consequences: from evaluating the accuracy of the program by verifying
logic, to the ability to customize code, to future debugging and reuse.
As we discussed earlier, this problem also exists for trained
developers.</p>
<p>One approach to address this issue is for the AI system to include
some notion of code readability or comprehensibility as a factor in code
synthesis, such as during the learning phase, or when ranking
suggestions, or even take it as input to the model (similar to the
‘temperature’ parameter in Codex). This approach is useful more broadly
to synthesize high quality code, such as optimizing for performance or
robustness. A second solution to tackle the comprehension problem is to
explain the generated code to their users in a manner that is less
‘programmerese’ and more centered around the user’s current task and
context. Initial evidence suggests that participants were open to these
ideas; thus, these areas are ripe for future exploration.</p>
<h3 data-number="9.4"
id="issue-4-consequences-of-automation-in-end-user-programming"><span
class="header-section-number">9.4</span> Issue 4: Consequences of
automation in end-user programming</h3>
<p>In any AI system, we need to consider the consequences of automation.
End-user programmers are known to turn to local experts or gardeners
(end-user programmers with interest and expertise in programming who
serve as gurus in the end-user programming environment) when they are
unable to solve a part of the problem <span class="citation"
data-cites="nardiEUPbook sarkar2018people">(Nardi 1993; Sarkar and
Gordon 2018)</span>. Task-orientation tendencies combined with
challenges of completing their tasks easily also leaves end-user
programmers with limited attention for testing, or carefully learning
what is going on with their programs. Assuming that LLMs and associated
user experiences will improve in the coming years, making end-user
programming faster with LLMs than without, it is tempting to wonder
whether the programmer can be persuaded to invest the saved time and
attention to aspects such as learning or testing their programs; if so,
what would it take to influence behaviour changes?</p>
<p>Another question is in the role of such experts. We conjecture that
LLMs or similar AI capabilities will soon be able to answer a sizeable
fraction of questions that end-user programmers will go to local experts
for. An open question therefore is how the ecosystem of end-user
programmers in organizations will change in their roles, importance and
specialities. For example, will gardeners take on the role of educating
users on better taking advantage of AI? If so, how can we communicate
the working of such AI systems to technophile users and early adopters,
so they can enable others in the organization?</p>
<h3 data-number="9.5"
id="issue-5-no-code-and-the-dilemma-of-the-direct-answer"><span
class="header-section-number">9.5</span> Issue 5: No code, and the
dilemma of the direct answer</h3>
<p>Finally, it is not a foregone conclusion that users are even
interested in code. As Blackwell’s model of attention investment notes,
in many cases the user may be content to perform an action manually,
rather than invest in creating a reusable automation <span
class="citation"
data-cites="blackwell2002first williams2020understanding">(Blackwell
2002a; J. Williams et al. 2020)</span>. Spreadsheet users, in
particular, are often not sensitive to the level of automation or
automatability of a given workflow, using a mix of manual, automated,
and semi-automated techniques to achieve the goal at hand <span
class="citation" data-cites="pandita2018no">(Pandita et al.
2018)</span>.</p>
<p>Spreadsheet users often need ad-hoc transformations of their data
that they will, in all likelihood, never need again. It may be that we
can express this transformation as a program, but if the user is
interested in the output and not the program, is it important, or even
necessary, to communicate this fact to the user? One can argue that
increasing the user’s awareness of the flexibility and fallibility of
the process of delivering an inferred result (i.e., enabling them to
<em>critically evaluate</em> the output <span class="citation"
data-cites="sarkar2015interactive">(Sarkar et al. 2015)</span>) can
build agency, confidence, trust, and resilience. This issue is related
to information retrieval’s “dilemma of the direct answer” <span
class="citation" data-cites="potthast2021dilemma">(Potthast, Hagen, and
Stein 2021)</span>, raised in response to the increased phenomenon of
search engines directly answering queries in addition to simply listing
retrieved results.</p>
<p>However, if the programming language used is not related to the
languages familiar to the end-user, or the user is a complete novice, it
is exceedingly difficult for them to make any sense of it, as was shown
by <span class="citation" data-cites="lau2021tweakit">Lau et al.
(2021)</span> in their study of Excel users encountering Python code.
Yet, there are socio-technical motivations for using an unfamiliar
target language: long-term testing of LLM assistance shows that it
shines when paired with high-level APIs that capture use cases well
(Section <a href="#sec:experience_reports" data-reference-type="ref"
data-reference="sec:experience_reports">7</a>). One advantage of the
Python ecosystem is that it has an unparalleled set of libraries and
APIs for data wrangling. An LLM-assisted tool that emits Excel formulas
is therefore less likely to solve user problems than Python statements.
In the longer term, this might be mitigated by developing a rich set of
data manipulation libraries in the Excel formula language.</p>
<h2 data-number="10" id="sec:conclusion"><span
class="header-section-number">10</span> Conclusion</h2>
<p>Large language models have initiated a significant change in the
scope and quality of program code that can be automatically generated,
compared to previous approaches. Experience with commercially available
tools built on these models suggests that a they represent a new way of
programming. LLM assistance transforms almost every aspect of the
experience of programming, including planning, authoring, reuse,
modification, comprehension, and debugging.</p>
<p>In some aspects, LLM assistance resembles a highly intelligent and
flexible compiler, or a partner in pair programming, or a seamless
search-and-reuse feature. Yet in other aspects, LLM-assisted programming
has a flavour all of its own, which presents new challenges and
opportunities for human-centric programming research. Moreover, there
are even greater challenges in helping non-expert end users benefit from
such tools.</p>
<h2 data-number="11" id="apx:experience_report_sources"><span
class="header-section-number">A.</span> Experience report sources</h2>
<p>This appendix contains a list of sources we draw upon for the quotes
and analysis in Section <a href="#sec:experience_reports"
data-reference-type="ref" data-reference="sec:experience_reports">7</a>.
While all sources were included in our analysis, we did not draw direct
quotes from every source in this list.</p>
<h3 data-number="11.1"
id="blog-posts-and-corresponding-hacker-news-discussions"><span
class="header-section-number">A.1</span> Blog posts and corresponding
Hacker News discussions</h3>
<ol>
<li><p>Andrew Mayne, March 17 2022, “Building games and apps entirely
through natural language using OpenAI’s code-davinci model”. URL: <a
href="https://andrewmayneblog.wordpress.com/2022/03/17/building-games-and-apps-entirely-through-natural-language-using-openais-davinci-code-model/"
class="uri">https://andrewmayneblog.wordpress.com/2022/03/17/building-games-and-apps-entirely-through-natural-language-using-openais-davinci-code-model/</a>.
Hacker News discussion: <a
href="https://news.ycombinator.com/item?id=30717773"
class="uri">https://news.ycombinator.com/item?id=30717773</a></p></li>
<li><p>Andrew Mouboussin, March 24 2022, “Building a No-Code Machine
Learning Model by Chatting with GitHub Copilot”. URL: <a
href="https://www.surgehq.ai/blog/building-a-no-code-toxicity-classifier-by-talking-to-copilot"
class="uri">https://www.surgehq.ai/blog/building-a-no-code-toxicity-classifier-by-talking-to-copilot</a>.
Hacker News discussion: <a
href="https://news.ycombinator.com/item?id=30797381"
class="uri">https://news.ycombinator.com/item?id=30797381</a></p></li>
<li><p>Matt Rickard, August 17 2021, “One Month of Using GitHub
Copilot”. URL: <a
href="https://matt-rickard.com/github-copilot-a-month-in/"
class="uri">https://matt-rickard.com/github-copilot-a-month-in/</a>.</p></li>
<li><p>Nutanc, November 15 2021, “Using Github copilot to get the tweets
for a keyword and find the sentiment of each tweet in 2 mins”. URL: <a
href="https://nutanc.medium.com/using-github-copilot-to-get-the-tweets-for-a-keyword-and-find-the-sentiment-of-each-tweet-in-2-mins-9a531abedc84"
class="uri">https://nutanc.medium.com/using-github-copilot-to-get-the-tweets-for-a-keyword-and-find-the-sentiment-of-each-tweet-in-2-mins-9a531abedc84</a>.</p></li>
<li><p>Tanishq Abraham, July 14 2021, “Coding with GitHub Copilot”. URL:
<a href="https://tmabraham.github.io/blog/github_copilot"
class="uri">https://tmabraham.github.io/blog/github_copilot</a>.</p></li>
<li><p>Aleksej Komnenovic, January 17 2022, “Don’t fully trust AI in dev
work! /yet”. URL: <a
href="https://akom.me/dont-fully-trust-ai-in-dev-work-yet"
class="uri">https://akom.me/dont-fully-trust-ai-in-dev-work-yet</a>.</p></li>
</ol>
<h3 data-number="11.2" id="miscellaneous-hacker-news-discussions"><span
class="header-section-number">A.2</span> Miscellaneous Hacker News
discussions</h3>
<ol>
<li><p><a href="https://news.ycombinator.com/item?id=30747211"
class="uri">https://news.ycombinator.com/item?id=30747211</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31390371"
class="uri">https://news.ycombinator.com/item?id=31390371</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31020229&amp;p=2"
class="uri">https://news.ycombinator.com/item?id=31020229&amp;p=2</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=29760171"
class="uri">https://news.ycombinator.com/item?id=29760171</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31325154"
class="uri">https://news.ycombinator.com/item?id=31325154</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31734110"
class="uri">https://news.ycombinator.com/item?id=31734110</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31652939"
class="uri">https://news.ycombinator.com/item?id=31652939</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=30682841"
class="uri">https://news.ycombinator.com/item?id=30682841</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31515938"
class="uri">https://news.ycombinator.com/item?id=31515938</a></p></li>
<li><p><a href="https://news.ycombinator.com/item?id=31825742"
class="uri">https://news.ycombinator.com/item?id=31825742</a></p></li>
</ol>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-DBLP:journals/csur/AllamanisBDS18" class="csl-entry"
role="doc-biblioentry">
Allamanis, Miltiadis, Earl T. Barr, Premkumar T. Devanbu, and Charles
Sutton. 2018. <span>“A Survey of Machine Learning for Big Code and
Naturalness.”</span> <em><span>ACM</span> Comput. Surv.</em> 51 (4):
81:1–37. <a
href="https://doi.org/10.1145/3212695">https://doi.org/10.1145/3212695</a>.
</div>
<div id="ref-allamanis2017smartpaste" class="csl-entry"
role="doc-biblioentry">
Allamanis, Miltiadis, and Marc Brockschmidt. 2017. <span>“Smartpaste:
Learning to Adapt Source Code.”</span> <em>arXiv Preprint
arXiv:1705.07867</em>.
</div>
<div id="ref-austin2021mbpp" class="csl-entry" role="doc-biblioentry">
Austin, Jacob, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk
Michalewski, David Dohan, Ellen Jiang, et al. 2021. <span>“Program
Synthesis with Large Language Models.”</span> arXiv. <a
href="https://doi.org/10.48550/ARXIV.2108.07732">https://doi.org/10.48550/ARXIV.2108.07732</a>.
</div>
<div id="ref-barik2018should" class="csl-entry" role="doc-biblioentry">
Barik, Titus, Denae Ford, Emerson Murphy-Hill, and Chris Parnin. 2018.
<span>“How Should Compilers Explain Problems to Developers?”</span> In
<em>Proceedings of the 2018 26th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software
Engineering</em>, 633–43.
</div>
<div id="ref-barik2015heart" class="csl-entry" role="doc-biblioentry">
Barik, Titus, Brittany Johnson, and Emerson Murphy-Hill. 2015. <span>“I
Heart Hacker News: Expanding Qualitative Research Findings by Analyzing
Social News Websites.”</span> In <em>Proceedings of the 2015 10th Joint
Meeting on Foundations of Software Engineering</em>, 882–85.
</div>
<div id="ref-barke2022grounded" class="csl-entry"
role="doc-biblioentry">
Barke, Shraddha, Michael B. James, and Nadia Polikarpova. 2022.
<span>“Grounded Copilot: How Programmers Interact with Code-Generating
Models.”</span> arXiv. <a
href="https://doi.org/10.48550/ARXIV.2206.15000">https://doi.org/10.48550/ARXIV.2206.15000</a>.
</div>
<div id="ref-basman2016software" class="csl-entry"
role="doc-biblioentry">
Basman, Antranig, Luke Church, Clemens Nylandsted Klokmose, and Colin BD
Clark. 2016. <span>“Software and How It Lives on-Embedding Live Programs
in the World Around Them.”</span> In <em>PPIG</em>, 19.
</div>
<div id="ref-DBLP:conf/fat/BenderGMS21" class="csl-entry"
role="doc-biblioentry">
Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021. <span>“On the Dangers of Stochastic Parrots: Can
Language Models Be Too Big?”</span> In <em>FAccT ’21: 2021
<span>ACM</span> Conference on Fairness, Accountability, and
Transparency, Virtual Event / Toronto, Canada, March 3-10, 2021</em>,
edited by Madeleine Clare Elish, William Isaac, and Richard S. Zemel,
610–23. <span>ACM</span>. <a
href="https://doi.org/10.1145/3442188.3445922">https://doi.org/10.1145/3442188.3445922</a>.
</div>
<div id="ref-bergstrom2016practices" class="csl-entry"
role="doc-biblioentry">
Bergström, Ilias, and Alan F Blackwell. 2016. <span>“The Practices of
Programming.”</span> In <em>2016 IEEE Symposium on Visual Languages and
Human-Centric Computing (VL/HCC)</em>, 190–98. IEEE.
</div>
<div id="ref-blackwell2002first" class="csl-entry"
role="doc-biblioentry">
Blackwell, Alan F. 2002a. <span>“First Steps in Programming: A Rationale
for Attention Investment Models.”</span> In <em>Proceedings IEEE 2002
Symposia on Human Centric Computing Languages and Environments</em>,
2–10. IEEE.
</div>
<div id="ref-blackwell2002programming" class="csl-entry"
role="doc-biblioentry">
———. 2002b. <span>“What Is Programming?”</span> In <em>PPIG</em>, 20.
Citeseer.
</div>
<div id="ref-DBLP:journals/interactions/Bodker15" class="csl-entry"
role="doc-biblioentry">
Bødker, Susanne. 2015. <span>“Third-Wave HCI, 10 Years Later -
Participation and Sharing.”</span> <em>Interactions</em> 22 (5): 24–31.
<a
href="https://doi.org/10.1145/2804405">https://doi.org/10.1145/2804405</a>.
</div>
<div id="ref-brown2020language" class="csl-entry"
role="doc-biblioentry">
Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language
Models Are Few-Shot Learners.”</span> <a
href="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</a>.
</div>
<div id="ref-cao2015idea" class="csl-entry" role="doc-biblioentry">
Cao, Jill, Scott D Fleming, Margaret Burnett, and Christopher Scaffidi.
2015. <span>“Idea Garden: Situated Support for Problem Solving by
End-User Programmers.”</span> <em>Interacting with Computers</em> 27
(6): 640–60.
</div>
<div id="ref-chalhoub2022freedom" class="csl-entry"
role="doc-biblioentry">
Chalhoub, George, and Advait Sarkar. 2022. <span>“<span
class="nocase"><span>‘It’s Freedom to Put Things Where My Mind
Wants’</span>: Understanding and Improving the User Experience of
Structuring Data in Spreadsheets</span>.”</span> In <em><span
class="nocase">CHI Conference on Human Factors in Computing
Systems</span></em>. CHI ’22. New York, NY, USA: Association for
Computing Machinery. <a
href="https://doi.org/10.1145/3491102.3501833">https://doi.org/10.1145/3491102.3501833</a>.
</div>
<div id="ref-chen2021codex" class="csl-entry" role="doc-biblioentry">
Chen, Mark, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de
Oliveira Pinto, Jared Kaplan, Harrison Edwards, et al. 2021.
<span>“Evaluating Large Language Models Trained on Code.”</span>
<em>CoRR</em> abs/2107.03374. <a
href="https://arxiv.org/abs/2107.03374">https://arxiv.org/abs/2107.03374</a>.
</div>
<div id="ref-Chen2021EvaluatingLL" class="csl-entry"
role="doc-biblioentry">
Chen, Mark, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared
Kaplan, Harrison Edwards, et al. 2021. <span>“Evaluating Large Language
Models Trained on Code.”</span> <em>ArXiv</em> abs/2107.03374.
</div>
<div id="ref-Chowdhery2022PaLMSL" class="csl-entry"
role="doc-biblioentry">
Chowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav
Mishra, Adam Roberts, Paul Barham, et al. 2022. <span>“PaLM: Scaling
Language Modeling with Pathways.”</span> <em>ArXiv</em> abs/2204.02311.
</div>
<div id="ref-colmerauer1996birth" class="csl-entry"
role="doc-biblioentry">
Colmerauer, Alain, and Philippe Roussel. 1996. <span>“The Birth of
Prolog.”</span> In <em>History of Programming Languages—II</em>, 331–67.
</div>
<div id="ref-devlin-etal-2019-bert" class="csl-entry"
role="doc-biblioentry">
Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
<span>“<span>BERT</span>: Pre-Training of Deep Bidirectional
Transformers for Language Understanding.”</span> In <em>Proceedings of
the 2019 Conference of the North <span>A</span>merican Chapter of the
Association for Computational Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers)</em>, 4171–86. Minneapolis, Minnesota:
Association for Computational Linguistics. <a
href="https://doi.org/10.18653/v1/N19-1423">https://doi.org/10.18653/v1/N19-1423</a>.
</div>
<div id="ref-green1989cognitive" class="csl-entry"
role="doc-biblioentry">
Green, Thomas RG. 1989. <span>“Cognitive Dimensions of
Notations.”</span> <em>People and Computers V</em>, 443–60.
</div>
<div id="ref-green1992visual" class="csl-entry" role="doc-biblioentry">
Green, Thomas RG, and Marian Petre. 1992. <span>“When Visual Programs
Are Harder to Read Than Textual Programs.”</span> In <em>Human-Computer
Interaction: Tasks and Organisation, Proceedings of ECCE-6 (6th European
Conference on Cognitive Ergonomics). GC van Der Veer, MJ Tauber, s.
Bagnarola and m. Antavolits. Rome, CUD</em>, 167–80. Citeseer.
</div>
<div id="ref-green1998cognitive" class="csl-entry"
role="doc-biblioentry">
Green, Thomas, and Alan Blackwell. 1998. <span>“Cognitive Dimensions of
Information Artefacts: A Tutorial.”</span> In <em>BCS HCI
Conference</em>, 98:1–75.
</div>
<div id="ref-DBLP:conf/popl/Gulwani11" class="csl-entry"
role="doc-biblioentry">
Gulwani, Sumit. 2011. <span>“Automating String Processing in
Spreadsheets Using Input-Output Examples.”</span> In <em>Proceedings of
the 38th <span>ACM</span> <span>SIGPLAN-SIGACT</span> Symposium on
Principles of Programming Languages, <span>POPL</span> 2011, Austin, TX,
USA, January 26-28, 2011</em>, edited by Thomas Ball and Mooly Sagiv,
317–30. <span>ACM</span>. <a
href="https://doi.org/10.1145/1926385.1926423">https://doi.org/10.1145/1926385.1926423</a>.
</div>
<div id="ref-hannay2009effectiveness" class="csl-entry"
role="doc-biblioentry">
Hannay, Jo E, Tore Dybå, Erik Arisholm, and Dag IK Sjøberg. 2009.
<span>“The Effectiveness of Pair Programming: A Meta-Analysis.”</span>
<em>Information and Software Technology</em> 51 (7): 1110–22.
</div>
<div id="ref-henley2014patchworks" class="csl-entry"
role="doc-biblioentry">
Henley, Austin Z, and Scott D Fleming. 2014. <span>“The Patchworks Code
Editor: Toward Faster Navigation with Less Code Arranging and Fewer
Navigation Mistakes.”</span> In <em>Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems</em>, 2511–20.
</div>
<div id="ref-hermans2015detecting" class="csl-entry"
role="doc-biblioentry">
Hermans, Felienne, Martin Pinzger, and Arie van Deursen. 2015.
<span>“Detecting and Refactoring Code Smells in Spreadsheet
Formulas.”</span> <em>Empirical Software Engineering</em> 20 (2):
549–75.
</div>
<div id="ref-DBLP:journals/cacm/HindleBGS16" class="csl-entry"
role="doc-biblioentry">
Hindle, Abram, Earl T. Barr, Mark Gabel, Zhendong Su, and Premkumar T.
Devanbu. 2016. <span>“On the Naturalness of Software.”</span>
<em>Commun. <span>ACM</span></em> 59 (5): 122–31. <a
href="https://doi.org/10.1145/2902362">https://doi.org/10.1145/2902362</a>.
</div>
<div id="ref-DBLP:conf/icse/HindleBSGD12" class="csl-entry"
role="doc-biblioentry">
Hindle, Abram, Earl T. Barr, Zhendong Su, Mark Gabel, and Premkumar T.
Devanbu. 2012. <span>“On the Naturalness of Software.”</span> In
<em>34th International Conference on Software Engineering,
<span>ICSE</span> 2012, June 2-9, 2012, Zurich, Switzerland</em>, edited
by Martin Glinz, Gail C. Murphy, and Mauro Pezzè, 837–47.
<span>IEEE</span> Computer Society. <a
href="https://doi.org/10.1109/ICSE.2012.6227135">https://doi.org/10.1109/ICSE.2012.6227135</a>.
</div>
<div id="ref-DBLP:journals/cacm/Hoare69" class="csl-entry"
role="doc-biblioentry">
Hoare, C. A. R. 1969. <span>“An Axiomatic Basis for Computer
Programming.”</span> <em>Commun. <span>ACM</span></em> 12 (10): 576–80.
<a
href="https://doi.org/10.1145/363235.363259">https://doi.org/10.1145/363235.363259</a>.
</div>
<div id="ref-10.1162/neco.1997.9.8.1735" class="csl-entry"
role="doc-biblioentry">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term
Memory.”</span> <em>Neural Comput.</em> 9 (8): 1735–80. <a
href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.
</div>
<div id="ref-horvitz1999principles" class="csl-entry"
role="doc-biblioentry">
Horvitz, Eric. 1999. <span>“Principles of Mixed-Initiative User
Interfaces.”</span> In <em>Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems</em>, 159–66.
</div>
<div id="ref-DBLP:journals/hhci/HutchinsHN85" class="csl-entry"
role="doc-biblioentry">
Hutchins, Edwin L., James D. Hollan, and Donald A. Norman. 1985.
<span>“Direct Manipulation Interfaces.”</span> <em>Hum. Comput.
Interact.</em> 1 (4): 311–38. <a
href="https://doi.org/10.1207/s15327051hci0104\_2">https://doi.org/10.1207/s15327051hci0104\_2</a>.
</div>
<div id="ref-imai2022github" class="csl-entry" role="doc-biblioentry">
Imai, Saki. 2022. <span>“Is GitHub Copilot a Substitute for Human
Pair-Programming? An Empirical Study.”</span> In <em>2022 IEEE/ACM 44th
International Conference on Software Engineering: Companion Proceedings
(ICSE-Companion)</em>, 319–21. IEEE.
</div>
<div id="ref-jiang2022discovering" class="csl-entry"
role="doc-biblioentry">
Jiang, Ellen, Edwin Toh, Alejandra Molina, Kristen Olson, Claire
Kayacik, Aaron Donsbach, Carrie J Cai, and Michael Terry. 2022.
<span>“Discovering the Syntax and Strategies of Natural Language
Programming with Generative Language Models.”</span> In <em>CHI
Conference on Human Factors in Computing Systems</em>, 1–19.
</div>
<div id="ref-kery2017exploring" class="csl-entry"
role="doc-biblioentry">
Kery, Mary Beth, and Brad A Myers. 2017. <span>“Exploring Exploratory
Programming.”</span> In <em>2017 IEEE Symposium on Visual Languages and
Human-Centric Computing (VL/HCC)</em>, 25–29. IEEE.
</div>
<div id="ref-ko2004designing" class="csl-entry" role="doc-biblioentry">
Ko, Amy J, and Brad A Myers. 2004. <span>“Designing the Whyline: A
Debugging Interface for Asking Questions about Program Behavior.”</span>
In <em>Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems</em>, 151–58.
</div>
<div id="ref-kulesza2014structured" class="csl-entry"
role="doc-biblioentry">
Kulesza, Todd, Saleema Amershi, Rich Caruana, Danyel Fisher, and Denis
Charles. 2014. <span>“Structured Labeling for Facilitating Concept
Evolution in Machine Learning.”</span> In <em>Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems</em>, 3075–84.
</div>
<div id="ref-kurlander1993watch" class="csl-entry"
role="doc-biblioentry">
Kurlander, David, Allen Cypher, and Daniel Conrad Halbert. 1993.
<em>Watch What i Do: Programming by Demonstration</em>. MIT press.
</div>
<div id="ref-lau2021tweakit" class="csl-entry" role="doc-biblioentry">
Lau, Sam, Sruti Srinivasa Srinivasa Ragavan, Ken Milne, Titus Barik, and
Advait Sarkar. 2021. <span>“Tweakit: Supporting End-User Programmers Who
Transmogrify Code.”</span> In <em><span class="nocase">Proceedings of
the 2021 CHI Conference on Human Factors in Computing
Systems</span></em>, 1–12.
</div>
<div id="ref-ijcai2021-612" class="csl-entry" role="doc-biblioentry">
Li, Junyi, Tianyi Tang, Wayne Xin Zhao, and Ji-Rong Wen. 2021.
<span>“Pretrained Language Model for Text Generation: A Survey.”</span>
In <em>Proceedings of the Thirtieth International Joint Conference on
Artificial Intelligence, <span>IJCAI-21</span></em>, edited by Zhi-Hua
Zhou, 4492–99. International Joint Conferences on Artificial
Intelligence Organization. <a
href="https://doi.org/10.24963/ijcai.2021/612">https://doi.org/10.24963/ijcai.2021/612</a>.
</div>
<div id="ref-Li2022CompetitionLevelCG" class="csl-entry"
role="doc-biblioentry">
Li, Yujia, David H. Choi, Junyoung Chung, Nate Kushman, Julian
Schrittwieser, Rémi Leblond, Tom, et al. 2022. <span>“Competition-Level
Code Generation with AlphaCode.”</span> <em>ArXiv</em> abs/2203.07814.
</div>
<div id="ref-li2022:alphacode" class="csl-entry" role="doc-biblioentry">
Li, Yujia, David Choi, Junyoung Chung, Nate Kushman, Julian
Schrittwieser, Rémi Leblond, Tom Eccles, et al. 2022.
<span>“Competition-Level Code Generation with AlphaCode.”</span> arXiv.
<a
href="https://doi.org/10.48550/ARXIV.2203.07814">https://doi.org/10.48550/ARXIV.2203.07814</a>.
</div>
<div id="ref-lieberman2001your" class="csl-entry"
role="doc-biblioentry">
Lieberman, Henry. 2001. <em>Your Wish Is My Command: Programming by
Example</em>. Morgan Kaufmann.
</div>
<div id="ref-lieberman2006feasibility" class="csl-entry"
role="doc-biblioentry">
Lieberman, Henry, and Hugo Liu. 2006. <span>“Feasibility Studies for
Programming in Natural Language.”</span> In <em>End User
Development</em>, 459–73. Springer.
</div>
<div id="ref-liu2021retrievalaugmented" class="csl-entry"
role="doc-biblioentry">
Liu, Shangqing, Yu Chen, Xiaofei Xie, Jing Kai Siow, and Yang Liu. 2021.
<span>“Retrieval-Augmented Generation for Code Summarization via Hybrid
<span>GNN</span>.”</span> In <em>International Conference on Learning
Representations</em>. <a
href="https://openreview.net/forum?id=zv-typ1gPxA">https://openreview.net/forum?id=zv-typ1gPxA</a>.
</div>
<div id="ref-Lu2021CodeXGLUEAM" class="csl-entry"
role="doc-biblioentry">
Lu, Shuai, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy,
Ambrosio Blanco, Colin B. Clement, et al. 2021. <span>“CodeXGLUE: A
Machine Learning Benchmark Dataset for Code Understanding and
Generation.”</span> <em>ArXiv</em> abs/2102.04664.
</div>
<div id="ref-luger2016like" class="csl-entry" role="doc-biblioentry">
Luger, Ewa, and Abigail Sellen. 2016. <span>“"Like Having a Really Bad
PA" the Gulf Between User Expectation and Experience of Conversational
Agents.”</span> In <em>Proceedings of the 2016 CHI Conference on Human
Factors in Computing Systems</em>, 5286–97.
</div>
<div id="ref-macvean2016api" class="csl-entry" role="doc-biblioentry">
Macvean, Andrew, Luke Church, John Daughtry, and Craig Citro. 2016.
<span>“API Usability at Scale.”</span> In <em>PPIG</em>, 26.
</div>
<div id="ref-madi2022readable" class="csl-entry" role="doc-biblioentry">
Madi, Naser Al. 2022. <span>“How Readable Is Model-Generated Code?
Examining Readability and Visual Inspection of GitHub Copilot.”</span>
<em>arXiv Preprint arXiv:2208.14613</em>.
</div>
<div id="ref-marasoiu2015empirical" class="csl-entry"
role="doc-biblioentry">
Marasoiu, Mariana, Luke Church, and Alan Blackwell. 2015. <span>“An
Empirical Investigation of Code Completion Usage by Professional
Software Developers.”</span> In <em><span>PPIG</span></em>.
</div>
<div id="ref-NIPS2013_9aa42b31" class="csl-entry"
role="doc-biblioentry">
Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean.
2013. <span>“Distributed Representations of Words and Phrases and Their
Compositionality.”</span> In <em>Advances in Neural Information
Processing Systems</em>, edited by C. J. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger. Vol. 26. Curran Associates, Inc. <a
href="https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf</a>.
</div>
<div id="ref-miller1981natural" class="csl-entry"
role="doc-biblioentry">
Miller, Lance A. 1981. <span>“Natural Language Programming: Styles,
Strategies, and Contrasts.”</span> <em>IBM Systems Journal</em> 20 (2):
184–215.
</div>
<div id="ref-Mou2016ConvolutionalNN" class="csl-entry"
role="doc-biblioentry">
Mou, Lili, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. 2016.
<span>“Convolutional Neural Networks over Tree Structures for
Programming Language Processing.”</span> In <em>AAAI</em>.
</div>
<div id="ref-mu2019we" class="csl-entry" role="doc-biblioentry">
Mu, Jesse, and Advait Sarkar. 2019. <span>“<span class="nocase">Do we
need natural language? Exploring restricted language interfaces for
complex domains</span>.”</span> In <em><span class="nocase">Extended
Abstracts of the 2019 CHI Conference on Human Factors in Computing
Systems</span></em>, 1–6.
</div>
<div id="ref-myers1992demonstrational" class="csl-entry"
role="doc-biblioentry">
Myers, Brad A. 1992. <span>“Demonstrational Interfaces: A Step Beyond
Direct Manipulation.”</span> <em>Computer</em> 25 (8): 61–73.
</div>
<div id="ref-myers2016improving" class="csl-entry"
role="doc-biblioentry">
Myers, Brad A, and Jeffrey Stylos. 2016. <span>“Improving API
Usability.”</span> <em>Communications of the ACM</em> 59 (6): 62–69.
</div>
<div id="ref-nardiEUPbook" class="csl-entry" role="doc-biblioentry">
Nardi, Bonnie A. 1993. <em>A Small Matter of Programming: Perspectives
on End User Computing</em>. MIT press.
</div>
<div id="ref-Nguyen2015DivideandConquerAF" class="csl-entry"
role="doc-biblioentry">
Nguyen, Anh Tuan, Tung Thanh Nguyen, and Tien Nhut Nguyen. 2015.
<span>“Divide-and-Conquer Approach for Multi-Phase Statistical Migration
for Source Code (t).”</span> <em>2015 30th IEEE/ACM International
Conference on Automated Software Engineering (ASE)</em>, 585–96.
</div>
<div id="ref-pandita2018no" class="csl-entry" role="doc-biblioentry">
Pandita, Rahul, Chris Parnin, Felienne Hermans, and Emerson Murphy-Hill.
2018. <span>“No Half-Measures: A Study of Manual and Tool-Assisted
End-User Programming Tasks in Excel.”</span> In <em>2018 IEEE Symposium
on Visual Languages and Human-Centric Computing (VL/HCC)</em>, 95–103.
IEEE.
</div>
<div id="ref-panko2008reducing" class="csl-entry"
role="doc-biblioentry">
Panko, Raymond R. 2008. <span>“Reducing Overconfidence in Spreadsheet
Development.”</span> <em>arXiv Preprint arXiv:0804.0941</em>.
</div>
<div id="ref-pearce2021copilotsecurity" class="csl-entry"
role="doc-biblioentry">
Pearce, Hammond, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, and
Ramesh Karri. 2021. <span>“Asleep at the Keyboard? Assessing the
Security of GitHub Copilot’s Code Contributions.”</span> arXiv. <a
href="https://doi.org/10.48550/ARXIV.2108.09293">https://doi.org/10.48550/ARXIV.2108.09293</a>.
</div>
<div id="ref-piccioni2013empirical" class="csl-entry"
role="doc-biblioentry">
Piccioni, Marco, Carlo A Furia, and Bertrand Meyer. 2013. <span>“An
Empirical Study of API Usability.”</span> In <em>2013 ACM/IEEE
International Symposium on Empirical Software Engineering and
Measurement</em>, 5–14. IEEE.
</div>
<div id="ref-potthast2021dilemma" class="csl-entry"
role="doc-biblioentry">
Potthast, Martin, Matthias Hagen, and Benno Stein. 2021. <span>“The
Dilemma of the Direct Answer.”</span> In <em>ACM SIGIR Forum</em>,
54:1–12. 1. ACM New York, NY, USA.
</div>
<div id="ref-DBLP:conf/popl/RaychevVK15" class="csl-entry"
role="doc-biblioentry">
Raychev, Veselin, Martin T. Vechev, and Andreas Krause. 2015.
<span>“Predicting Program Properties from "Big Code".”</span> In
<em>Proceedings of the 42nd Annual <span>ACM</span>
<span>SIGPLAN-SIGACT</span> Symposium on Principles of Programming
Languages, <span>POPL</span> 2015, Mumbai, India, January 15-17,
2015</em>, edited by Sriram K. Rajamani and David Walker, 111–24.
<span>ACM</span>. <a
href="https://doi.org/10.1145/2676726.2677009">https://doi.org/10.1145/2676726.2677009</a>.
</div>
<div id="ref-rouchy2006aspects" class="csl-entry"
role="doc-biblioentry">
Rouchy, Philippe. 2006. <span>“Aspects of PROLOG History: Logic
Programming and Professional Dynamics.”</span> <em>Blekinge Institute of
Technology, Sweden).(English). TeamEthno-Online</em>, no. 2: 85–100.
</div>
<div id="ref-salge2016pair" class="csl-entry" role="doc-biblioentry">
Salge, Carolina Alves De Lima, and Nicholas Berente. 2016. <span>“Pair
Programming Vs. Solo Programming: What Do We Know After 15 Years of
Research?”</span> In <em>2016 49th Hawaii International Conference on
System Sciences (HICSS)</em>, 5398–5406. IEEE.
</div>
<div id="ref-sarkar2016phd" class="csl-entry" role="doc-biblioentry">
Sarkar, Advait. 2016. <span>“<span class="nocase">Interactive analytical
modelling</span>.”</span> UCAM-CL-TR-920. University of Cambridge,
Computer Laboratory. <a
href="https://doi.org/10.48456/tr-920">https://doi.org/10.48456/tr-920</a>.
</div>
<div id="ref-sarkar2022explainable" class="csl-entry"
role="doc-biblioentry">
Sarkar, Advait. 2022. <span>“<span class="nocase">Is explainable AI a race against
model complexity?</span>”</span> In <em><span class="nocase">Workshop on
Transparency and Explanations in Smart Systems (TeXSS), in conjunction
with ACM Intelligent User Interfaces (IUI 2022)</span></em>, 192–99.
CEUR Workshop Proceedings 3124. <a
href="http://ceur-ws.org/Vol-3124/paper22.pdf">http://ceur-ws.org/Vol-3124/paper22.pdf</a>.
</div>
<div id="ref-sarkar2018people" class="csl-entry" role="doc-biblioentry">
Sarkar, Advait, and Andrew D. Gordon. 2018. <span>“How Do People Learn
to Use Spreadsheets? (Work in Progress).”</span> In <em><span
class="nocase">Proceedings of the 29th Annual Conference of the
Psychology of Programming Interest Group (PPIG 2018)</span></em>, 28–35.
</div>
<div id="ref-sarkar2015interactive" class="csl-entry"
role="doc-biblioentry">
Sarkar, Advait, Mateja Jamnik, Alan F Blackwell, and Martin Spott. 2015.
<span>“Interactive Visual Machine Learning in Spreadsheets.”</span> In
<em><span class="nocase">2015 IEEE Symposium on Visual Languages and
Human-Centric Computing (VL/HCC)</span></em>, 159–63. IEEE.
</div>
<div id="ref-sarkar2022lambdas" class="csl-entry"
role="doc-biblioentry">
Sarkar, Advait, Sruti Srinivasa Ragavan, Jack Williams, and Andrew D.
Gordon. 2022. <span>“<span class="nocase">End-user encounters with
lambda abstraction in spreadsheets: Apollo’s bow or Achilles’
heel?</span>”</span> In <em><span class="nocase">2022 IEEE Symposium on
Visual Languages and Human-Centric Computing (VL/HCC)</span></em>. IEEE.
</div>
<div id="ref-shneiderman1993direct" class="csl-entry"
role="doc-biblioentry">
Shneiderman, B, and NJ Norwood. 1993. <span>“1.1 Direct Manipulation: A
Step Beyond Programming.”</span> <em>Sparks of Innovation in
Human-Computer Interaction</em>, 17.
</div>
<div id="ref-silver_2018" class="csl-entry" role="doc-biblioentry">
Silver, Amanda. 2018. <span>“Introducing Visual Studio
IntelliCode.”</span> <em>Visual Studio Blog</em>. Microsoft. <a
href="https://devblogs.microsoft.com/visualstudio/introducing-visual-studio-intellicode/">https://devblogs.microsoft.com/visualstudio/introducing-visual-studio-intellicode/</a>.
</div>
<div id="ref-ragavan2022gridbook" class="csl-entry"
role="doc-biblioentry">
Srinivasa Ragavan, Sruti, Zhitao Hou, Yun Wang, Andrew D Gordon, Haidong
Zhang, and Dongmei Zhang. 2022. <span>“GridBook: Natural Language
Formulas for the Spreadsheet Grid.”</span> In <em>27th International
Conference on Intelligent User Interfaces</em>, 345–68. IUI ’22. New
York, NY, USA: Association for Computing Machinery. <a
href="https://doi.org/10.1145/3490099.3511161">https://doi.org/10.1145/3490099.3511161</a>.
</div>
<div id="ref-srinivasa2016foraging" class="csl-entry"
role="doc-biblioentry">
Srinivasa Ragavan, Sruti, Sandeep Kaur Kuttal, Charles Hill, Anita
Sarma, David Piorkowski, and Margaret Burnett. 2016. <span>“Foraging
Among an Overabundance of Similar Variants.”</span> In <em>Proceedings
of the 2016 CHI Conference on Human Factors in Computing Systems</em>,
3509–21.
</div>
<div id="ref-10.5555/2969033.2969173" class="csl-entry"
role="doc-biblioentry">
Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. 2014. <span>“Sequence to
Sequence Learning with Neural Networks.”</span> In <em>Proceedings of
the 27th International Conference on Neural Information Processing
Systems - Volume 2</em>, 3104–12. NIPS’14. Cambridge, MA, USA: MIT
Press.
</div>
<div id="ref-tanimoto2013perspective" class="csl-entry"
role="doc-biblioentry">
Tanimoto, Steven L. 2013. <span>“A Perspective on the Evolution of Live
Programming.”</span> In <em>2013 1st International Workshop on Live
Programming (LIVE)</em>, 31–34. IEEE.
</div>
<div id="ref-vaithilingam2022expectation" class="csl-entry"
role="doc-biblioentry">
Vaithilingam, Priyan, Tianyi Zhang, and Elena L Glassman. 2022.
<span>“Expectation Vs. Experience: Evaluating the Usability of Code
Generation Tools Powered by Large Language Models.”</span> In <em>CHI
Conference on Human Factors in Computing Systems Extended
Abstracts</em>, 1–7.
</div>
<div id="ref-10.5555/3295222.3295349" class="csl-entry"
role="doc-biblioentry">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.
<span>“Attention Is All You Need.”</span> In <em>Proceedings of the 31st
International Conference on Neural Information Processing Systems</em>,
6000–6010. NIPS’17. Red Hook, NY, USA: Curran Associates Inc.
</div>
<div id="ref-Wei2020LambdaNetPT" class="csl-entry"
role="doc-biblioentry">
Wei, Jiayi, Maruth Goyal, Greg Durrett, and Isil Dillig. 2020.
<span>“LambdaNet: Probabilistic Type Inference Using Graph Neural
Networks.”</span> <em>ArXiv</em> abs/2005.02161.
</div>
<div id="ref-wei2015building" class="csl-entry" role="doc-biblioentry">
Wei, Yi, Nirupama Chandrasekaran, Sumit Gulwani, and Youssef Hamadi.
2015. <span>“Building Bing Developer Assistant.”</span> MSR-TR-2015-36.
<a
href="https://www.microsoft.com/en-us/research/publication/building-bing-developer-assistant/">https://www.microsoft.com/en-us/research/publication/building-bing-developer-assistant/</a>.
</div>
<div id="ref-weiss_2022" class="csl-entry" role="doc-biblioentry">
Weiss, Dror. 2022. <span>“Blog / Tabnine Announcements / Announcing Our
Next-Generation AI Models.”</span> <em>Tabnine.com</em>. Tabnine. <a
href="https://www.tabnine.com/blog/announcing-tabnine-next-generation/">https://www.tabnine.com/blog/announcing-tabnine-next-generation/</a>.
</div>
<div id="ref-williams2020understanding" class="csl-entry"
role="doc-biblioentry">
Williams, Jack, Carina Negreanu, Andrew D Gordon, and Advait Sarkar.
2020. <span>“Understanding and Inferring Units in Spreadsheets.”</span>
In <em><span class="nocase">2020 IEEE Symposium on Visual Languages and
Human-Centric Computing (VL/HCC)</span></em>, 1–9. IEEE Computer
Society.
</div>
<div id="ref-williams2000all" class="csl-entry" role="doc-biblioentry">
Williams, Laurie A, and Robert R Kessler. 2000. <span>“All i Really Need
to Know about Pair Programming i Learned in Kindergarten.”</span>
<em>Communications of the ACM</em> 43 (5): 108–14.
</div>
<div id="ref-wing2011computationalthinking" class="csl-entry"
role="doc-biblioentry">
Wing, Jeanette. 2011. <span>“Research Notebook: Computational
Thinking—What and Why.”</span> <em>The Link Magazine</em> 6: 20–23.
</div>
<div id="ref-Xu2022ASE" class="csl-entry" role="doc-biblioentry">
Xu, Frank F., Uri Alon, Graham Neubig, and Vincent J. Hellendoorn. 2022.
<span>“A Systematic Evaluation of Large Language Models of Code.”</span>
<em>Proceedings of the 6th ACM SIGPLAN International Symposium on
Machine Programming</em>.
</div>
<div id="ref-xu2022ide" class="csl-entry" role="doc-biblioentry">
Xu, Frank F, Bogdan Vasilescu, and Graham Neubig. 2022. <span>“<span
class="nocase">In-IDE Code Generation from Natural Language: Promise and
Challenges</span>.”</span> <em>ACM Transactions on Software Engineering
and Methodology (TOSEM)</em> 31 (2): 1–47.
</div>
<div id="ref-yoon2015supporting" class="csl-entry"
role="doc-biblioentry">
Yoon, YoungSeok, and Brad A Myers. 2015. <span>“Supporting Selective
Undo in a Code Editor.”</span> In <em>2015 IEEE/ACM 37th IEEE
International Conference on Software Engineering</em>, 1:223–33. IEEE.
</div>
<div id="ref-zhang2016bing" class="csl-entry" role="doc-biblioentry">
Zhang, Hongyu, Anuj Jain, Gaurav Khandelwal, Chandrashekhar Kaushik,
Scott Ge, and Wenxiang Hu. 2016. <span>“Bing Developer Assistant:
Improving Developer Productivity by Recommending Sample Code.”</span> In
<em>Proceedings of the 2016 24th ACM SIGSOFT International Symposium on
Foundations of Software Engineering</em>, 956–61.
</div>
<div id="ref-ziegler_2021" class="csl-entry" role="doc-biblioentry">
Ziegler, Albert. 2021. <span>“GitHub Copilot Research
Recitation.”</span> <em>The GitHub Blog</em>. Microsoft. <a
href="https://github.blog/2021-06-30-github-copilot-research-recitation/">https://github.blog/2021-06-30-github-copilot-research-recitation/</a>.
</div>
<div id="ref-ziegler2022productivity" class="csl-entry"
role="doc-biblioentry">
Ziegler, Albert, Eirini Kalliamvakou, Shawn Simister, Ganesh
Sittampalam, Alice Li, Andrew Rice, Devon Rifkin, and Edward
Aftandilian. 2022. <span>“Productivity Assessment of Neural Code
Completion.”</span> <em>arXiv Preprint arXiv:2205.06537</em>.
</div>
</div>
<section class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://commoncrawl.org/"
class="uri">https://commoncrawl.org/</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="http://pretrain.nlpedia.ai/"
class="uri">http://pretrain.nlpedia.ai/</a><a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a
href="https://huggingface.co/docs/transformers/main/model_doc/gptj"
class="uri">https://huggingface.co/docs/transformers/main/model_doc/gptj</a><a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a
href="https://huggingface.co/blog/codeparrot"
class="uri">https://huggingface.co/blog/codeparrot</a><a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><a href="https://copilot.github.com/"
class="uri">https://copilot.github.com/</a><a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p><a
href="https://aws.amazon.com/codewhisperer/features/"
class="uri">https://aws.amazon.com/codewhisperer/features/</a><a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p><a href="https://www.tabnine.com/"
class="uri">https://www.tabnine.com/</a><a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>As of 15 June 2022, Tabnine has
announced a shift to language model-driven autocompletion that more
closely resembles the abilities of Copilot <span class="citation"
data-cites="weiss_2022">(Weiss 2022)</span>.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>